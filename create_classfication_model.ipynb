{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 X_train amount\n",
      "111 X_valid amount\n",
      "53 X_test amount\n",
      "(131, 64, 64) X_train shape\n",
      "(111, 64, 64) X_valid shape\n",
      "(53, 64, 64) X_test shape\n",
      "(64, 64, 1) shape\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import  Conv1D, Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam\n",
    "from matplotlib import pyplot as plt\n",
    "import keras\n",
    "import keras.callbacks as KC\n",
    "\n",
    "cat_dir = 'clean_images/cat_images/'\n",
    "dog_dir = 'clean_images/dog_images/'\n",
    "SIZE = 64 #100->64\n",
    "TRAIN_RATIO = 0.8\n",
    "RESHAPED = 0\n",
    "NB_CLASSES = 2\n",
    "OPTIMIZER = SGD()\n",
    "BATCH_SIZE = 131\n",
    "NB_EPOCH = 100\n",
    "VALIDATION_SPLIT = 0.4\n",
    "VERBOSE = 1\n",
    "COLOR_MODE = 0\n",
    "USE_DATAGEN = False\n",
    "\n",
    "if USE_DATAGEN:\n",
    "    aug_str = 'with_aug'\n",
    "else:\n",
    "    aug_str = 'without_aug'\n",
    "\n",
    "if COLOR_MODE == 0:\n",
    "    color_mode = 'gray'\n",
    "else:\n",
    "    color_mode = 'color'\n",
    "    \n",
    "SAVED_MODEL_PATH = 'models/cat_dog_classfication_{}_{}_model.hdf5'.format(aug_str, color_mode)\n",
    "IMG_PATH = 'chart/{}_{}.png'.format(aug_str, color_mode)\n",
    "\n",
    "def prepare_data():\n",
    "    # 猫(0)と犬(1)の画像を取得してフラグを追加したにシャッフル加工してデータとして返す。\n",
    "    \n",
    "    images = []\n",
    "    cat_answers = []\n",
    "    dog_answers = []\n",
    "    cat_images = []\n",
    "    dog_images = []\n",
    "    validation_images = []\n",
    "    validation_answers = []\n",
    "\n",
    "    cat_files = glob.glob(os.path.join(cat_dir, '*.jpg'))\n",
    "    cat_files.sort()\n",
    "    dog_files = glob.glob(os.path.join(dog_dir, '*.jpg'))\n",
    "    dog_files.sort()\n",
    "\n",
    "    for cat_image in cat_files:\n",
    "        if cat_image.endswith('.jpg'):\n",
    "            cat_images.append(resize_for_model(cv2.imread(cat_image, COLOR_MODE)))\n",
    "            cat_answers.append(0)\n",
    "\n",
    "    for dog_image in dog_files:\n",
    "        if dog_image.endswith('.jpg'):\n",
    "            dog_images.append(resize_for_model(cv2.imread(dog_image, COLOR_MODE)))\n",
    "            dog_answers.append(1)\n",
    "\n",
    "    test_border_cat = int(len(cat_images) * (1 - TRAIN_RATIO))\n",
    "    test_border_dog = int(len(dog_images) * (1 - TRAIN_RATIO))\n",
    "    \n",
    "    test_images = np.array(cat_images[:test_border_cat] + dog_images[:test_border_dog])\n",
    "    test_answers = np.array(cat_answers[:test_border_cat] + dog_answers[:test_border_dog])\n",
    "            \n",
    "    validation_border_cat = test_border_cat + int(len(cat_images) * TRAIN_RATIO * VALIDATION_SPLIT)\n",
    "    validation_border_dog = test_border_dog + int(len(dog_images) * TRAIN_RATIO * VALIDATION_SPLIT)\n",
    "\n",
    "    validation_images = np.array(cat_images[test_border_cat:test_border_cat + validation_border_cat] + dog_images[test_border_dog:validation_border_dog])\n",
    "    validation_answers = np.array(cat_answers[test_border_cat:test_border_cat + validation_border_cat] + dog_answers[test_border_dog:validation_border_dog])\n",
    "    train_images = np.array(cat_images[validation_border_cat:] + dog_images[validation_border_dog:])\n",
    "    train_answers = np.array(cat_answers[validation_border_cat:] + dog_answers[validation_border_dog:])\n",
    "\n",
    "    # imagesとanswersの関係保ったままシャッフル\n",
    "    data = []\n",
    "    for images, answers in ((train_images, train_answers), (validation_images, validation_answers), (test_images, test_answers)):\n",
    "        random_idxs = np.random.permutation(len(images))\n",
    "        images = images[random_idxs]\n",
    "        answers = answers[random_idxs]\n",
    "        data.append([images, answers])\n",
    "    \n",
    "    return (data[0][0], data[0][1]), (data[1][0], data[1][1]), (data[2][0], data[2][1])\n",
    "\n",
    "def resize_for_model(image):\n",
    "    # np形式のimageを特定の大きさにresizeする。\n",
    "    return cv2.resize(image, (SIZE, SIZE))\n",
    "\n",
    "def remove_log_files(dir):\n",
    "    files = glob.glob(os.path.join(dir, '*.local'))\n",
    "    for file in files:\n",
    "        os.remove(file)\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    (X_train, y_train),(X_valid, y_valid), (X_test, y_test) = prepare_data()\n",
    "    print(len(X_train), 'X_train amount')\n",
    "    print(len(X_valid), 'X_valid amount')    \n",
    "    print(len(X_test), 'X_test amount')\n",
    "    print(X_train.shape, 'X_train shape')\n",
    "    print(X_valid.shape, 'X_valid shape')    \n",
    "    print(X_test.shape, 'X_test shape')\n",
    "    if len(X_train.shape) > 3:\n",
    "        SHAPE = (X_train.shape[1], X_train.shape[2], X_train.shape[3])\n",
    "    else:\n",
    "        SHAPE = (X_train.shape[1], X_train.shape[2], 1)\n",
    "    print(SHAPE, 'shape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHAPE[2] == 1:\n",
    "    X_train = X_train.reshape(X_train.shape[0],  SIZE, SIZE, 1)\n",
    "    X_valid = X_valid.reshape(X_valid.shape[0],  SIZE, SIZE, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0],  SIZE, SIZE, 1)\n",
    "\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_valid = X_valid.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_valid /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_valid = np_utils.to_categorical(y_valid, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [KC.TensorBoard()\n",
    "                     ,KC.ModelCheckpoint(filepath=SAVED_MODEL_PATH,\n",
    "                                                           verbose=1,\n",
    "                                                           save_weights_only=True,\n",
    "                                                           save_best_only=True,\n",
    "                                                           period=10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image  import ImageDataGenerator\n",
    "\n",
    "if USE_DATAGEN:\n",
    "    datagen = ImageDataGenerator(featurewise_center=True,\n",
    "                                                            featurewise_std_normalization=True,\n",
    "                                                            rotation_range=20,\n",
    "                                                            width_shift_range=0.2,\n",
    "                                                            height_shift_range=0.2,\n",
    "                                                            horizontal_flip=True)\n",
    "\n",
    "    datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#参考: https://keras.io/getting-started/sequential-model-guide/\n",
    "model = Sequential()\n",
    "\n",
    "if COLOR_MODE == 1: #color\n",
    "    FILTERS = 16\n",
    "    # with 3 channels\n",
    "    model.add(Conv2D(FILTERS, 3, activation='relu', input_shape=SHAPE))\n",
    "    model.add(Conv2D(FILTERS, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "else: #gray\n",
    "    # model for gray without datagen\n",
    "    FILTERS = 16\n",
    "    model.add(Conv2D(FILTERS, 3, activation='relu', input_shape=SHAPE))\n",
    "    model.add(Conv2D(FILTERS, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "#この層無い方がマシっぽい\n",
    "# model.add(Conv2D(UNITS * 2, (3, 3), activation='relu'))\n",
    "# model.add(Conv2D(UNITS * 2, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dropout(0.6)) #無い方が良い\n",
    "model.add(Dense(NB_CLASSES, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 131 samples, validate on 111 samples\n",
      "Epoch 1/400\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.7139 - acc: 0.4656 - val_loss: 0.7070 - val_acc: 0.3874\n",
      "Epoch 2/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.7257 - acc: 0.4504 - val_loss: 0.6974 - val_acc: 0.4775\n",
      "Epoch 3/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6840 - acc: 0.5649 - val_loss: 0.6979 - val_acc: 0.4685\n",
      "Epoch 4/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.7079 - acc: 0.5420 - val_loss: 0.7021 - val_acc: 0.4234\n",
      "Epoch 5/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6851 - acc: 0.5191 - val_loss: 0.7078 - val_acc: 0.4144\n",
      "Epoch 6/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6882 - acc: 0.5649 - val_loss: 0.7134 - val_acc: 0.3874\n",
      "Epoch 7/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.7064 - acc: 0.5267 - val_loss: 0.7139 - val_acc: 0.3964\n",
      "Epoch 8/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6982 - acc: 0.5420 - val_loss: 0.7118 - val_acc: 0.4054\n",
      "Epoch 9/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.7017 - acc: 0.4809 - val_loss: 0.7078 - val_acc: 0.3784\n",
      "Epoch 10/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6619 - acc: 0.5573 - val_loss: 0.7032 - val_acc: 0.4414\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.66530\n",
      "Epoch 11/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.7279 - acc: 0.4427 - val_loss: 0.6995 - val_acc: 0.4234\n",
      "Epoch 12/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.7003 - acc: 0.5573 - val_loss: 0.6970 - val_acc: 0.4685\n",
      "Epoch 13/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6897 - acc: 0.5496 - val_loss: 0.6973 - val_acc: 0.4685\n",
      "Epoch 14/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6739 - acc: 0.6412 - val_loss: 0.6988 - val_acc: 0.4865\n",
      "Epoch 15/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.7062 - acc: 0.5344 - val_loss: 0.6999 - val_acc: 0.4324\n",
      "Epoch 16/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.6614 - acc: 0.6031 - val_loss: 0.7012 - val_acc: 0.4324\n",
      "Epoch 17/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6657 - acc: 0.6412 - val_loss: 0.7037 - val_acc: 0.4414\n",
      "Epoch 18/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6941 - acc: 0.5344 - val_loss: 0.7065 - val_acc: 0.4595\n",
      "Epoch 19/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6882 - acc: 0.5496 - val_loss: 0.7089 - val_acc: 0.4595\n",
      "Epoch 20/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6652 - acc: 0.5954 - val_loss: 0.7121 - val_acc: 0.4685\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.66530\n",
      "Epoch 21/400\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.6648 - acc: 0.6031 - val_loss: 0.7135 - val_acc: 0.4685\n",
      "Epoch 22/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.6788 - acc: 0.5649 - val_loss: 0.7128 - val_acc: 0.4685\n",
      "Epoch 23/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6634 - acc: 0.5802 - val_loss: 0.7103 - val_acc: 0.4775\n",
      "Epoch 24/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6621 - acc: 0.6107 - val_loss: 0.7065 - val_acc: 0.4685\n",
      "Epoch 25/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6656 - acc: 0.6107 - val_loss: 0.7019 - val_acc: 0.5045\n",
      "Epoch 26/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6581 - acc: 0.6107 - val_loss: 0.6989 - val_acc: 0.4955\n",
      "Epoch 27/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6883 - acc: 0.5420 - val_loss: 0.6970 - val_acc: 0.5225\n",
      "Epoch 28/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6716 - acc: 0.5954 - val_loss: 0.6965 - val_acc: 0.5225\n",
      "Epoch 29/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6532 - acc: 0.6183 - val_loss: 0.6977 - val_acc: 0.5315\n",
      "Epoch 30/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6423 - acc: 0.6412 - val_loss: 0.6985 - val_acc: 0.5315\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.66530\n",
      "Epoch 31/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6642 - acc: 0.6260 - val_loss: 0.6989 - val_acc: 0.5315\n",
      "Epoch 32/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6459 - acc: 0.6794 - val_loss: 0.7006 - val_acc: 0.5135\n",
      "Epoch 33/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6498 - acc: 0.6412 - val_loss: 0.7020 - val_acc: 0.4955\n",
      "Epoch 34/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6301 - acc: 0.6336 - val_loss: 0.7033 - val_acc: 0.5045\n",
      "Epoch 35/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.6532 - acc: 0.6107 - val_loss: 0.7044 - val_acc: 0.5135\n",
      "Epoch 36/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6613 - acc: 0.6260 - val_loss: 0.7039 - val_acc: 0.5045\n",
      "Epoch 37/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6423 - acc: 0.6641 - val_loss: 0.7037 - val_acc: 0.4955\n",
      "Epoch 38/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.6385 - acc: 0.6489 - val_loss: 0.7025 - val_acc: 0.5045\n",
      "Epoch 39/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6360 - acc: 0.6412 - val_loss: 0.7012 - val_acc: 0.5225\n",
      "Epoch 40/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6614 - acc: 0.5954 - val_loss: 0.7002 - val_acc: 0.5225\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.66530\n",
      "Epoch 41/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6198 - acc: 0.6565 - val_loss: 0.7012 - val_acc: 0.5225\n",
      "Epoch 42/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6353 - acc: 0.6641 - val_loss: 0.7023 - val_acc: 0.5225\n",
      "Epoch 43/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.5971 - acc: 0.7023 - val_loss: 0.7029 - val_acc: 0.5135\n",
      "Epoch 44/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6004 - acc: 0.7252 - val_loss: 0.7035 - val_acc: 0.5135\n",
      "Epoch 45/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.6437 - acc: 0.6489 - val_loss: 0.7036 - val_acc: 0.5135\n",
      "Epoch 46/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6244 - acc: 0.6718 - val_loss: 0.7042 - val_acc: 0.5135\n",
      "Epoch 47/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6422 - acc: 0.6489 - val_loss: 0.7048 - val_acc: 0.5135\n",
      "Epoch 48/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.5888 - acc: 0.7252 - val_loss: 0.7046 - val_acc: 0.5315\n",
      "Epoch 49/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.6056 - acc: 0.6794 - val_loss: 0.7034 - val_acc: 0.5225\n",
      "Epoch 50/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.6096 - acc: 0.6565 - val_loss: 0.7034 - val_acc: 0.5225\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.66530\n",
      "Epoch 51/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.6138 - acc: 0.6870 - val_loss: 0.7031 - val_acc: 0.5225\n",
      "Epoch 52/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6144 - acc: 0.6870 - val_loss: 0.7033 - val_acc: 0.5225\n",
      "Epoch 53/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6150 - acc: 0.6794 - val_loss: 0.7035 - val_acc: 0.5225\n",
      "Epoch 54/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6182 - acc: 0.6870 - val_loss: 0.7041 - val_acc: 0.5225\n",
      "Epoch 55/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6204 - acc: 0.6565 - val_loss: 0.7045 - val_acc: 0.5225\n",
      "Epoch 56/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6134 - acc: 0.6260 - val_loss: 0.7058 - val_acc: 0.5225\n",
      "Epoch 57/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.6080 - acc: 0.6947 - val_loss: 0.7070 - val_acc: 0.5225\n",
      "Epoch 58/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.6001 - acc: 0.6870 - val_loss: 0.7086 - val_acc: 0.5225\n",
      "Epoch 59/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.5893 - acc: 0.7023 - val_loss: 0.7100 - val_acc: 0.5225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.6091 - acc: 0.6794 - val_loss: 0.7108 - val_acc: 0.5225\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.66530\n",
      "Epoch 61/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.6211 - acc: 0.6260 - val_loss: 0.7108 - val_acc: 0.5225\n",
      "Epoch 62/400\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.6155 - acc: 0.7023 - val_loss: 0.7083 - val_acc: 0.5225\n",
      "Epoch 63/400\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.6215 - acc: 0.6336 - val_loss: 0.7054 - val_acc: 0.5315\n",
      "Epoch 64/400\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.6145 - acc: 0.6718 - val_loss: 0.7035 - val_acc: 0.5405\n",
      "Epoch 65/400\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.5663 - acc: 0.7252 - val_loss: 0.7018 - val_acc: 0.5405\n",
      "Epoch 66/400\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.5981 - acc: 0.7176 - val_loss: 0.7030 - val_acc: 0.5405\n",
      "Epoch 67/400\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.5847 - acc: 0.7176 - val_loss: 0.7059 - val_acc: 0.5315\n",
      "Epoch 68/400\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.6033 - acc: 0.6718 - val_loss: 0.7083 - val_acc: 0.5315\n",
      "Epoch 69/400\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.5916 - acc: 0.6641 - val_loss: 0.7088 - val_acc: 0.5315\n",
      "Epoch 70/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.5847 - acc: 0.6947 - val_loss: 0.7075 - val_acc: 0.5315\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.66530\n",
      "Epoch 71/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.5745 - acc: 0.7176 - val_loss: 0.7064 - val_acc: 0.5315\n",
      "Epoch 72/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.5894 - acc: 0.6870 - val_loss: 0.7063 - val_acc: 0.5315\n",
      "Epoch 73/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.5539 - acc: 0.7481 - val_loss: 0.7059 - val_acc: 0.5315\n",
      "Epoch 74/400\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.5739 - acc: 0.7176 - val_loss: 0.7045 - val_acc: 0.5495\n",
      "Epoch 75/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.5871 - acc: 0.7099 - val_loss: 0.7040 - val_acc: 0.5495\n",
      "Epoch 76/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.5689 - acc: 0.7099 - val_loss: 0.7055 - val_acc: 0.5405\n",
      "Epoch 77/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.5496 - acc: 0.7405 - val_loss: 0.7116 - val_acc: 0.5315\n",
      "Epoch 78/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.5723 - acc: 0.7252 - val_loss: 0.7150 - val_acc: 0.5225\n",
      "Epoch 79/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.5543 - acc: 0.7481 - val_loss: 0.7201 - val_acc: 0.5405\n",
      "Epoch 80/400\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.5405 - acc: 0.7176 - val_loss: 0.7228 - val_acc: 0.5405\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.66530\n",
      "Epoch 81/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.5641 - acc: 0.6947 - val_loss: 0.7197 - val_acc: 0.5225\n",
      "Epoch 82/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.5586 - acc: 0.7023 - val_loss: 0.7144 - val_acc: 0.5405\n",
      "Epoch 83/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.5774 - acc: 0.6947 - val_loss: 0.7093 - val_acc: 0.5586\n",
      "Epoch 84/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.5556 - acc: 0.6870 - val_loss: 0.7047 - val_acc: 0.5586\n",
      "Epoch 85/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.5524 - acc: 0.7023 - val_loss: 0.7020 - val_acc: 0.5676\n",
      "Epoch 86/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.5364 - acc: 0.7634 - val_loss: 0.7020 - val_acc: 0.5676\n",
      "Epoch 87/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.5460 - acc: 0.7099 - val_loss: 0.7062 - val_acc: 0.5676\n",
      "Epoch 88/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.5360 - acc: 0.7405 - val_loss: 0.7119 - val_acc: 0.5495\n",
      "Epoch 89/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.5647 - acc: 0.6947 - val_loss: 0.7176 - val_acc: 0.5405\n",
      "Epoch 90/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.5728 - acc: 0.7557 - val_loss: 0.7225 - val_acc: 0.5315\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.66530\n",
      "Epoch 91/400\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.5438 - acc: 0.7634 - val_loss: 0.7232 - val_acc: 0.5315\n",
      "Epoch 92/400\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.5254 - acc: 0.7710 - val_loss: 0.7201 - val_acc: 0.5405\n",
      "Epoch 93/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.5560 - acc: 0.7099 - val_loss: 0.7134 - val_acc: 0.5495\n",
      "Epoch 94/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.5283 - acc: 0.7481 - val_loss: 0.7069 - val_acc: 0.5676\n",
      "Epoch 95/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.5654 - acc: 0.7099 - val_loss: 0.7012 - val_acc: 0.5946\n",
      "Epoch 96/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.5184 - acc: 0.7786 - val_loss: 0.7013 - val_acc: 0.5946\n",
      "Epoch 97/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.5282 - acc: 0.7786 - val_loss: 0.7057 - val_acc: 0.5766\n",
      "Epoch 98/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.5187 - acc: 0.7939 - val_loss: 0.7124 - val_acc: 0.5495\n",
      "Epoch 99/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.5181 - acc: 0.7328 - val_loss: 0.7191 - val_acc: 0.5586\n",
      "Epoch 100/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.5186 - acc: 0.7710 - val_loss: 0.7250 - val_acc: 0.5676\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.66530\n",
      "Epoch 101/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.5368 - acc: 0.7252 - val_loss: 0.7283 - val_acc: 0.5766\n",
      "Epoch 102/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.5301 - acc: 0.7328 - val_loss: 0.7204 - val_acc: 0.5676\n",
      "Epoch 103/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.5103 - acc: 0.7863 - val_loss: 0.7104 - val_acc: 0.5676\n",
      "Epoch 104/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.5124 - acc: 0.7786 - val_loss: 0.7024 - val_acc: 0.6036\n",
      "Epoch 105/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.5211 - acc: 0.7863 - val_loss: 0.6961 - val_acc: 0.6126\n",
      "Epoch 106/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4981 - acc: 0.7863 - val_loss: 0.6939 - val_acc: 0.6126\n",
      "Epoch 107/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.5289 - acc: 0.7634 - val_loss: 0.6975 - val_acc: 0.6126\n",
      "Epoch 108/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.5059 - acc: 0.7786 - val_loss: 0.7035 - val_acc: 0.5856\n",
      "Epoch 109/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.5141 - acc: 0.7405 - val_loss: 0.7118 - val_acc: 0.5766\n",
      "Epoch 110/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.5272 - acc: 0.7252 - val_loss: 0.7183 - val_acc: 0.5946\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.66530\n",
      "Epoch 111/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4708 - acc: 0.8168 - val_loss: 0.7231 - val_acc: 0.5856\n",
      "Epoch 112/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4931 - acc: 0.7710 - val_loss: 0.7218 - val_acc: 0.5946\n",
      "Epoch 113/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.5112 - acc: 0.7481 - val_loss: 0.7116 - val_acc: 0.5946\n",
      "Epoch 114/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.5045 - acc: 0.7939 - val_loss: 0.7019 - val_acc: 0.5946\n",
      "Epoch 115/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.5202 - acc: 0.7786 - val_loss: 0.6973 - val_acc: 0.6126\n",
      "Epoch 116/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4889 - acc: 0.7863 - val_loss: 0.6981 - val_acc: 0.6126\n",
      "Epoch 117/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.4918 - acc: 0.7786 - val_loss: 0.7019 - val_acc: 0.5946\n",
      "Epoch 118/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4996 - acc: 0.7939 - val_loss: 0.7078 - val_acc: 0.5856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4827 - acc: 0.7939 - val_loss: 0.7137 - val_acc: 0.5946\n",
      "Epoch 120/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4676 - acc: 0.7939 - val_loss: 0.7180 - val_acc: 0.6036\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.66530\n",
      "Epoch 121/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.5048 - acc: 0.7710 - val_loss: 0.7240 - val_acc: 0.6036\n",
      "Epoch 122/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.4687 - acc: 0.8092 - val_loss: 0.7258 - val_acc: 0.6036\n",
      "Epoch 123/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4990 - acc: 0.7557 - val_loss: 0.7210 - val_acc: 0.6036\n",
      "Epoch 124/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4801 - acc: 0.8092 - val_loss: 0.7104 - val_acc: 0.6036\n",
      "Epoch 125/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.4648 - acc: 0.8092 - val_loss: 0.7000 - val_acc: 0.6126\n",
      "Epoch 126/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.4658 - acc: 0.8015 - val_loss: 0.6984 - val_acc: 0.6126\n",
      "Epoch 127/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4693 - acc: 0.7863 - val_loss: 0.6985 - val_acc: 0.6126\n",
      "Epoch 128/400\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.5026 - acc: 0.7710 - val_loss: 0.7005 - val_acc: 0.6036\n",
      "Epoch 129/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.5015 - acc: 0.7863 - val_loss: 0.7044 - val_acc: 0.6036\n",
      "Epoch 130/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4406 - acc: 0.8244 - val_loss: 0.7123 - val_acc: 0.5946\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.66530\n",
      "Epoch 131/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.4605 - acc: 0.8168 - val_loss: 0.7149 - val_acc: 0.6036\n",
      "Epoch 132/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.4595 - acc: 0.8092 - val_loss: 0.7174 - val_acc: 0.6126\n",
      "Epoch 133/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.4561 - acc: 0.8168 - val_loss: 0.7099 - val_acc: 0.6036\n",
      "Epoch 134/400\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.4642 - acc: 0.8168 - val_loss: 0.7059 - val_acc: 0.6126\n",
      "Epoch 135/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4432 - acc: 0.8321 - val_loss: 0.7050 - val_acc: 0.6126\n",
      "Epoch 136/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4567 - acc: 0.7863 - val_loss: 0.7062 - val_acc: 0.6126\n",
      "Epoch 137/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4697 - acc: 0.7786 - val_loss: 0.7065 - val_acc: 0.6126\n",
      "Epoch 138/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4502 - acc: 0.8168 - val_loss: 0.7060 - val_acc: 0.6126\n",
      "Epoch 139/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.4355 - acc: 0.8244 - val_loss: 0.7056 - val_acc: 0.6126\n",
      "Epoch 140/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4552 - acc: 0.8168 - val_loss: 0.7025 - val_acc: 0.6126\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.66530\n",
      "Epoch 141/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.4537 - acc: 0.8397 - val_loss: 0.7004 - val_acc: 0.6126\n",
      "Epoch 142/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.4470 - acc: 0.8397 - val_loss: 0.7037 - val_acc: 0.6126\n",
      "Epoch 143/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.4248 - acc: 0.8626 - val_loss: 0.7104 - val_acc: 0.6216\n",
      "Epoch 144/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4372 - acc: 0.8321 - val_loss: 0.7131 - val_acc: 0.6216\n",
      "Epoch 145/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4603 - acc: 0.8015 - val_loss: 0.7161 - val_acc: 0.6126\n",
      "Epoch 146/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4150 - acc: 0.8550 - val_loss: 0.7147 - val_acc: 0.6126\n",
      "Epoch 147/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4429 - acc: 0.8168 - val_loss: 0.7072 - val_acc: 0.6306\n",
      "Epoch 148/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4448 - acc: 0.8092 - val_loss: 0.7029 - val_acc: 0.6126\n",
      "Epoch 149/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4352 - acc: 0.8244 - val_loss: 0.7019 - val_acc: 0.6126\n",
      "Epoch 150/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4205 - acc: 0.8550 - val_loss: 0.7043 - val_acc: 0.6306\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.66530\n",
      "Epoch 151/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4198 - acc: 0.8473 - val_loss: 0.7087 - val_acc: 0.6306\n",
      "Epoch 152/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.4207 - acc: 0.8015 - val_loss: 0.7105 - val_acc: 0.6306\n",
      "Epoch 153/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.4552 - acc: 0.7557 - val_loss: 0.7087 - val_acc: 0.6306\n",
      "Epoch 154/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4156 - acc: 0.8397 - val_loss: 0.7014 - val_acc: 0.6216\n",
      "Epoch 155/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4185 - acc: 0.8015 - val_loss: 0.7003 - val_acc: 0.6216\n",
      "Epoch 156/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4124 - acc: 0.8626 - val_loss: 0.7011 - val_acc: 0.6306\n",
      "Epoch 157/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4280 - acc: 0.8397 - val_loss: 0.7006 - val_acc: 0.6306\n",
      "Epoch 158/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4044 - acc: 0.8168 - val_loss: 0.7006 - val_acc: 0.6306\n",
      "Epoch 159/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4218 - acc: 0.8168 - val_loss: 0.7025 - val_acc: 0.6306\n",
      "Epoch 160/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3935 - acc: 0.8473 - val_loss: 0.7052 - val_acc: 0.6306\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.66530\n",
      "Epoch 161/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3807 - acc: 0.8779 - val_loss: 0.7073 - val_acc: 0.6306\n",
      "Epoch 162/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4023 - acc: 0.8092 - val_loss: 0.7039 - val_acc: 0.6306\n",
      "Epoch 163/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4060 - acc: 0.8550 - val_loss: 0.6976 - val_acc: 0.6216\n",
      "Epoch 164/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3844 - acc: 0.8550 - val_loss: 0.6952 - val_acc: 0.6306\n",
      "Epoch 165/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4153 - acc: 0.8473 - val_loss: 0.6950 - val_acc: 0.6306\n",
      "Epoch 166/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3879 - acc: 0.8779 - val_loss: 0.7013 - val_acc: 0.6306\n",
      "Epoch 167/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3782 - acc: 0.8626 - val_loss: 0.7075 - val_acc: 0.6306\n",
      "Epoch 168/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4019 - acc: 0.8321 - val_loss: 0.7183 - val_acc: 0.6216\n",
      "Epoch 169/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.3980 - acc: 0.8473 - val_loss: 0.7227 - val_acc: 0.6126\n",
      "Epoch 170/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3733 - acc: 0.8931 - val_loss: 0.7135 - val_acc: 0.6306\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.66530\n",
      "Epoch 171/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.4056 - acc: 0.8321 - val_loss: 0.7083 - val_acc: 0.6306\n",
      "Epoch 172/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3910 - acc: 0.8397 - val_loss: 0.7045 - val_acc: 0.6306\n",
      "Epoch 173/400\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.3645 - acc: 0.8931 - val_loss: 0.6995 - val_acc: 0.6396\n",
      "Epoch 174/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.4075 - acc: 0.8244 - val_loss: 0.6975 - val_acc: 0.6577\n",
      "Epoch 175/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4039 - acc: 0.8397 - val_loss: 0.7044 - val_acc: 0.6306\n",
      "Epoch 176/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.3614 - acc: 0.9008 - val_loss: 0.7100 - val_acc: 0.6306\n",
      "Epoch 177/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.3650 - acc: 0.8702 - val_loss: 0.7153 - val_acc: 0.6216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3609 - acc: 0.8702 - val_loss: 0.7132 - val_acc: 0.6216\n",
      "Epoch 179/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3719 - acc: 0.8779 - val_loss: 0.7072 - val_acc: 0.6396\n",
      "Epoch 180/400\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.3765 - acc: 0.8702 - val_loss: 0.6980 - val_acc: 0.6577\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.66530\n",
      "Epoch 181/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.3864 - acc: 0.8702 - val_loss: 0.6921 - val_acc: 0.6396\n",
      "Epoch 182/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.4043 - acc: 0.8168 - val_loss: 0.6884 - val_acc: 0.6396\n",
      "Epoch 183/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3839 - acc: 0.8626 - val_loss: 0.6905 - val_acc: 0.6396\n",
      "Epoch 184/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3703 - acc: 0.8473 - val_loss: 0.6996 - val_acc: 0.6486\n",
      "Epoch 185/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3458 - acc: 0.9313 - val_loss: 0.7107 - val_acc: 0.6396\n",
      "Epoch 186/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.3523 - acc: 0.8779 - val_loss: 0.7163 - val_acc: 0.6216\n",
      "Epoch 187/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3524 - acc: 0.8931 - val_loss: 0.7156 - val_acc: 0.6216\n",
      "Epoch 188/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.3293 - acc: 0.9160 - val_loss: 0.7096 - val_acc: 0.6396\n",
      "Epoch 189/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.3221 - acc: 0.9084 - val_loss: 0.7042 - val_acc: 0.6396\n",
      "Epoch 190/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3405 - acc: 0.9160 - val_loss: 0.7029 - val_acc: 0.6486\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.66530\n",
      "Epoch 191/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.3474 - acc: 0.9084 - val_loss: 0.7039 - val_acc: 0.6486\n",
      "Epoch 192/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.3478 - acc: 0.8931 - val_loss: 0.7051 - val_acc: 0.6396\n",
      "Epoch 193/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.3257 - acc: 0.9160 - val_loss: 0.7020 - val_acc: 0.6577\n",
      "Epoch 194/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3212 - acc: 0.8931 - val_loss: 0.7008 - val_acc: 0.6577\n",
      "Epoch 195/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3547 - acc: 0.8550 - val_loss: 0.6996 - val_acc: 0.6667\n",
      "Epoch 196/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3563 - acc: 0.8779 - val_loss: 0.6988 - val_acc: 0.6667\n",
      "Epoch 197/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.3622 - acc: 0.8626 - val_loss: 0.6988 - val_acc: 0.6667\n",
      "Epoch 198/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3660 - acc: 0.8397 - val_loss: 0.7007 - val_acc: 0.6667\n",
      "Epoch 199/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3496 - acc: 0.8626 - val_loss: 0.7027 - val_acc: 0.6667\n",
      "Epoch 200/400\n",
      "131/131 [==============================] - 1s 4ms/step - loss: 0.3275 - acc: 0.8855 - val_loss: 0.7095 - val_acc: 0.6396\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.66530\n",
      "Epoch 201/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.3452 - acc: 0.8931 - val_loss: 0.7175 - val_acc: 0.6306\n",
      "Epoch 202/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.3463 - acc: 0.8931 - val_loss: 0.7203 - val_acc: 0.6306\n",
      "Epoch 203/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3459 - acc: 0.8931 - val_loss: 0.7141 - val_acc: 0.6306\n",
      "Epoch 204/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.3415 - acc: 0.8855 - val_loss: 0.7044 - val_acc: 0.6667\n",
      "Epoch 205/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.3441 - acc: 0.8779 - val_loss: 0.7019 - val_acc: 0.6667\n",
      "Epoch 206/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3225 - acc: 0.9313 - val_loss: 0.6995 - val_acc: 0.6667\n",
      "Epoch 207/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.3565 - acc: 0.8931 - val_loss: 0.6987 - val_acc: 0.6667\n",
      "Epoch 208/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3209 - acc: 0.9313 - val_loss: 0.7020 - val_acc: 0.6667\n",
      "Epoch 209/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3467 - acc: 0.8702 - val_loss: 0.7068 - val_acc: 0.6577\n",
      "Epoch 210/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.3311 - acc: 0.8855 - val_loss: 0.7113 - val_acc: 0.6486\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.66530\n",
      "Epoch 211/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3114 - acc: 0.9008 - val_loss: 0.7123 - val_acc: 0.6486\n",
      "Epoch 212/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.3158 - acc: 0.8931 - val_loss: 0.7092 - val_acc: 0.6486\n",
      "Epoch 213/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.3550 - acc: 0.8626 - val_loss: 0.7110 - val_acc: 0.6486\n",
      "Epoch 214/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3297 - acc: 0.8855 - val_loss: 0.7030 - val_acc: 0.6577\n",
      "Epoch 215/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3265 - acc: 0.8931 - val_loss: 0.6973 - val_acc: 0.6667\n",
      "Epoch 216/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.3104 - acc: 0.9237 - val_loss: 0.6941 - val_acc: 0.6577\n",
      "Epoch 217/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3018 - acc: 0.9237 - val_loss: 0.6932 - val_acc: 0.6667\n",
      "Epoch 218/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3344 - acc: 0.9008 - val_loss: 0.6932 - val_acc: 0.6667\n",
      "Epoch 219/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3034 - acc: 0.9008 - val_loss: 0.6946 - val_acc: 0.6577\n",
      "Epoch 220/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3035 - acc: 0.9084 - val_loss: 0.6974 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.66530\n",
      "Epoch 221/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3211 - acc: 0.9160 - val_loss: 0.7004 - val_acc: 0.6577\n",
      "Epoch 222/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.3174 - acc: 0.8931 - val_loss: 0.7028 - val_acc: 0.6577\n",
      "Epoch 223/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3012 - acc: 0.9237 - val_loss: 0.7038 - val_acc: 0.6577\n",
      "Epoch 224/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.3444 - acc: 0.8626 - val_loss: 0.7061 - val_acc: 0.6667\n",
      "Epoch 225/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2904 - acc: 0.9389 - val_loss: 0.7079 - val_acc: 0.6577\n",
      "Epoch 226/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3140 - acc: 0.8931 - val_loss: 0.7027 - val_acc: 0.6577\n",
      "Epoch 227/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2884 - acc: 0.9389 - val_loss: 0.6951 - val_acc: 0.6757\n",
      "Epoch 228/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3033 - acc: 0.8855 - val_loss: 0.6864 - val_acc: 0.6577\n",
      "Epoch 229/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.3000 - acc: 0.8931 - val_loss: 0.6846 - val_acc: 0.6486\n",
      "Epoch 230/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2724 - acc: 0.9389 - val_loss: 0.6889 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.66530\n",
      "Epoch 231/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2807 - acc: 0.9466 - val_loss: 0.6979 - val_acc: 0.6577\n",
      "Epoch 232/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.3265 - acc: 0.8855 - val_loss: 0.7083 - val_acc: 0.6577\n",
      "Epoch 233/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2686 - acc: 0.9237 - val_loss: 0.7116 - val_acc: 0.6577\n",
      "Epoch 234/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2874 - acc: 0.9160 - val_loss: 0.7044 - val_acc: 0.6667\n",
      "Epoch 235/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2926 - acc: 0.9313 - val_loss: 0.6926 - val_acc: 0.6667\n",
      "Epoch 236/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2957 - acc: 0.9237 - val_loss: 0.6846 - val_acc: 0.6577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2858 - acc: 0.8931 - val_loss: 0.6834 - val_acc: 0.6577\n",
      "Epoch 238/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2802 - acc: 0.9389 - val_loss: 0.6878 - val_acc: 0.6847\n",
      "Epoch 239/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2728 - acc: 0.9313 - val_loss: 0.6947 - val_acc: 0.6757\n",
      "Epoch 240/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2556 - acc: 0.9695 - val_loss: 0.6997 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.66530\n",
      "Epoch 241/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2774 - acc: 0.9313 - val_loss: 0.7033 - val_acc: 0.6667\n",
      "Epoch 242/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2773 - acc: 0.9313 - val_loss: 0.7062 - val_acc: 0.6667\n",
      "Epoch 243/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2592 - acc: 0.9389 - val_loss: 0.7090 - val_acc: 0.6577\n",
      "Epoch 244/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2722 - acc: 0.9313 - val_loss: 0.7109 - val_acc: 0.6577\n",
      "Epoch 245/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2835 - acc: 0.9237 - val_loss: 0.7095 - val_acc: 0.6577\n",
      "Epoch 246/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2640 - acc: 0.9618 - val_loss: 0.7014 - val_acc: 0.6667\n",
      "Epoch 247/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2885 - acc: 0.9160 - val_loss: 0.6915 - val_acc: 0.6757\n",
      "Epoch 248/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2499 - acc: 0.9389 - val_loss: 0.6807 - val_acc: 0.6486\n",
      "Epoch 249/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.2619 - acc: 0.9313 - val_loss: 0.6794 - val_acc: 0.6486\n",
      "Epoch 250/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2627 - acc: 0.9389 - val_loss: 0.6841 - val_acc: 0.6577\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.66530\n",
      "Epoch 251/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2702 - acc: 0.9237 - val_loss: 0.6935 - val_acc: 0.6847\n",
      "Epoch 252/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2846 - acc: 0.9237 - val_loss: 0.7102 - val_acc: 0.6577\n",
      "Epoch 253/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2225 - acc: 0.9695 - val_loss: 0.7195 - val_acc: 0.6577\n",
      "Epoch 254/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2352 - acc: 0.9389 - val_loss: 0.7235 - val_acc: 0.6577\n",
      "Epoch 255/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.2783 - acc: 0.9237 - val_loss: 0.7124 - val_acc: 0.6577\n",
      "Epoch 256/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2626 - acc: 0.9313 - val_loss: 0.6974 - val_acc: 0.6937\n",
      "Epoch 257/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.2763 - acc: 0.9466 - val_loss: 0.6865 - val_acc: 0.6577\n",
      "Epoch 258/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2646 - acc: 0.9237 - val_loss: 0.6833 - val_acc: 0.6486\n",
      "Epoch 259/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2745 - acc: 0.9237 - val_loss: 0.6877 - val_acc: 0.6577\n",
      "Epoch 260/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2401 - acc: 0.9389 - val_loss: 0.6940 - val_acc: 0.6847\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.66530\n",
      "Epoch 261/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2330 - acc: 0.9389 - val_loss: 0.7028 - val_acc: 0.6937\n",
      "Epoch 262/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2708 - acc: 0.9237 - val_loss: 0.7078 - val_acc: 0.6847\n",
      "Epoch 263/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2557 - acc: 0.9313 - val_loss: 0.7090 - val_acc: 0.6757\n",
      "Epoch 264/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2434 - acc: 0.9389 - val_loss: 0.7041 - val_acc: 0.7027\n",
      "Epoch 265/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2655 - acc: 0.9237 - val_loss: 0.6985 - val_acc: 0.6937\n",
      "Epoch 266/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.2516 - acc: 0.9237 - val_loss: 0.6924 - val_acc: 0.6577\n",
      "Epoch 267/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.2355 - acc: 0.9542 - val_loss: 0.6917 - val_acc: 0.6577\n",
      "Epoch 268/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.2766 - acc: 0.9313 - val_loss: 0.6964 - val_acc: 0.6577\n",
      "Epoch 269/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.2454 - acc: 0.9389 - val_loss: 0.6998 - val_acc: 0.6847\n",
      "Epoch 270/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2270 - acc: 0.9466 - val_loss: 0.7030 - val_acc: 0.7027\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.66530\n",
      "Epoch 271/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2480 - acc: 0.9313 - val_loss: 0.7083 - val_acc: 0.6937\n",
      "Epoch 272/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.2619 - acc: 0.9160 - val_loss: 0.7130 - val_acc: 0.6937\n",
      "Epoch 273/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2417 - acc: 0.9466 - val_loss: 0.7171 - val_acc: 0.6757\n",
      "Epoch 274/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2344 - acc: 0.9466 - val_loss: 0.7154 - val_acc: 0.6937\n",
      "Epoch 275/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2354 - acc: 0.9160 - val_loss: 0.7095 - val_acc: 0.6937\n",
      "Epoch 276/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2412 - acc: 0.9466 - val_loss: 0.6993 - val_acc: 0.6667\n",
      "Epoch 277/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2246 - acc: 0.9618 - val_loss: 0.6957 - val_acc: 0.6577\n",
      "Epoch 278/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.2327 - acc: 0.9466 - val_loss: 0.6993 - val_acc: 0.6667\n",
      "Epoch 279/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2529 - acc: 0.9466 - val_loss: 0.7105 - val_acc: 0.7027\n",
      "Epoch 280/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2300 - acc: 0.9466 - val_loss: 0.7213 - val_acc: 0.6847\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.66530\n",
      "Epoch 281/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2165 - acc: 0.9466 - val_loss: 0.7254 - val_acc: 0.6667\n",
      "Epoch 282/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2254 - acc: 0.9542 - val_loss: 0.7327 - val_acc: 0.6757\n",
      "Epoch 283/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2275 - acc: 0.9466 - val_loss: 0.7265 - val_acc: 0.6757\n",
      "Epoch 284/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.2156 - acc: 0.9695 - val_loss: 0.7102 - val_acc: 0.7027\n",
      "Epoch 285/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.2173 - acc: 0.9847 - val_loss: 0.7003 - val_acc: 0.6667\n",
      "Epoch 286/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2196 - acc: 0.9542 - val_loss: 0.6962 - val_acc: 0.6577\n",
      "Epoch 287/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1994 - acc: 0.9771 - val_loss: 0.6978 - val_acc: 0.6577\n",
      "Epoch 288/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.2304 - acc: 0.9542 - val_loss: 0.7067 - val_acc: 0.6757\n",
      "Epoch 289/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2088 - acc: 0.9618 - val_loss: 0.7181 - val_acc: 0.7027\n",
      "Epoch 290/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2349 - acc: 0.9313 - val_loss: 0.7246 - val_acc: 0.6847\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.66530\n",
      "Epoch 291/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2194 - acc: 0.9771 - val_loss: 0.7319 - val_acc: 0.6757\n",
      "Epoch 292/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2033 - acc: 0.9695 - val_loss: 0.7293 - val_acc: 0.6757\n",
      "Epoch 293/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2179 - acc: 0.9389 - val_loss: 0.7201 - val_acc: 0.7027\n",
      "Epoch 294/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2131 - acc: 0.9618 - val_loss: 0.7113 - val_acc: 0.6847\n",
      "Epoch 295/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2233 - acc: 0.9542 - val_loss: 0.7065 - val_acc: 0.6757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2325 - acc: 0.9008 - val_loss: 0.7056 - val_acc: 0.6667\n",
      "Epoch 297/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2135 - acc: 0.9466 - val_loss: 0.7076 - val_acc: 0.6757\n",
      "Epoch 298/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1908 - acc: 0.9618 - val_loss: 0.7124 - val_acc: 0.6847\n",
      "Epoch 299/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2149 - acc: 0.9695 - val_loss: 0.7202 - val_acc: 0.7027\n",
      "Epoch 300/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.2181 - acc: 0.9466 - val_loss: 0.7235 - val_acc: 0.6937\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.66530\n",
      "Epoch 301/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2219 - acc: 0.9313 - val_loss: 0.7182 - val_acc: 0.7027\n",
      "Epoch 302/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.2137 - acc: 0.9466 - val_loss: 0.7138 - val_acc: 0.6937\n",
      "Epoch 303/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.1983 - acc: 0.9466 - val_loss: 0.7114 - val_acc: 0.6847\n",
      "Epoch 304/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.2115 - acc: 0.9466 - val_loss: 0.7072 - val_acc: 0.6667\n",
      "Epoch 305/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2002 - acc: 0.9542 - val_loss: 0.7069 - val_acc: 0.6757\n",
      "Epoch 306/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2163 - acc: 0.9542 - val_loss: 0.7124 - val_acc: 0.6937\n",
      "Epoch 307/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2023 - acc: 0.9389 - val_loss: 0.7143 - val_acc: 0.6937\n",
      "Epoch 308/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2065 - acc: 0.9618 - val_loss: 0.7130 - val_acc: 0.6937\n",
      "Epoch 309/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1971 - acc: 0.9924 - val_loss: 0.7158 - val_acc: 0.6937\n",
      "Epoch 310/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2046 - acc: 0.9771 - val_loss: 0.7175 - val_acc: 0.6937\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.66530\n",
      "Epoch 311/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2111 - acc: 0.9466 - val_loss: 0.7181 - val_acc: 0.7027\n",
      "Epoch 312/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1883 - acc: 0.9924 - val_loss: 0.7177 - val_acc: 0.6937\n",
      "Epoch 313/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2011 - acc: 0.9618 - val_loss: 0.7182 - val_acc: 0.6937\n",
      "Epoch 314/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2059 - acc: 0.9389 - val_loss: 0.7142 - val_acc: 0.6937\n",
      "Epoch 315/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2023 - acc: 0.9466 - val_loss: 0.7155 - val_acc: 0.6847\n",
      "Epoch 316/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1926 - acc: 0.9695 - val_loss: 0.7177 - val_acc: 0.6937\n",
      "Epoch 317/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.2003 - acc: 0.9542 - val_loss: 0.7193 - val_acc: 0.6937\n",
      "Epoch 318/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1880 - acc: 0.9771 - val_loss: 0.7215 - val_acc: 0.6937\n",
      "Epoch 319/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1969 - acc: 0.9542 - val_loss: 0.7244 - val_acc: 0.6937\n",
      "Epoch 320/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1668 - acc: 0.9847 - val_loss: 0.7249 - val_acc: 0.6937\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.66530\n",
      "Epoch 321/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1766 - acc: 1.0000 - val_loss: 0.7229 - val_acc: 0.6937\n",
      "Epoch 322/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.1695 - acc: 0.9771 - val_loss: 0.7177 - val_acc: 0.6937\n",
      "Epoch 323/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1866 - acc: 0.9924 - val_loss: 0.7125 - val_acc: 0.6937\n",
      "Epoch 324/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1904 - acc: 0.9466 - val_loss: 0.7086 - val_acc: 0.6847\n",
      "Epoch 325/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1881 - acc: 0.9542 - val_loss: 0.7047 - val_acc: 0.6757\n",
      "Epoch 326/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1866 - acc: 0.9542 - val_loss: 0.7070 - val_acc: 0.6667\n",
      "Epoch 327/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1855 - acc: 0.9695 - val_loss: 0.7126 - val_acc: 0.6937\n",
      "Epoch 328/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1922 - acc: 0.9466 - val_loss: 0.7250 - val_acc: 0.7027\n",
      "Epoch 329/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1749 - acc: 0.9771 - val_loss: 0.7352 - val_acc: 0.6937\n",
      "Epoch 330/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1813 - acc: 0.9771 - val_loss: 0.7376 - val_acc: 0.6847\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.66530\n",
      "Epoch 331/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1864 - acc: 0.9542 - val_loss: 0.7330 - val_acc: 0.6847\n",
      "Epoch 332/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.1809 - acc: 0.9847 - val_loss: 0.7204 - val_acc: 0.6937\n",
      "Epoch 333/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1888 - acc: 0.9771 - val_loss: 0.7073 - val_acc: 0.6757\n",
      "Epoch 334/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1606 - acc: 0.9771 - val_loss: 0.7007 - val_acc: 0.6937\n",
      "Epoch 335/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.1873 - acc: 0.9466 - val_loss: 0.7019 - val_acc: 0.6937\n",
      "Epoch 336/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1690 - acc: 0.9847 - val_loss: 0.7057 - val_acc: 0.6847\n",
      "Epoch 337/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1842 - acc: 0.9542 - val_loss: 0.7153 - val_acc: 0.6937\n",
      "Epoch 338/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1904 - acc: 0.9695 - val_loss: 0.7256 - val_acc: 0.7117\n",
      "Epoch 339/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1713 - acc: 0.9847 - val_loss: 0.7307 - val_acc: 0.7117\n",
      "Epoch 340/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1575 - acc: 0.9847 - val_loss: 0.7313 - val_acc: 0.7117\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.66530\n",
      "Epoch 341/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.1796 - acc: 0.9542 - val_loss: 0.7238 - val_acc: 0.7027\n",
      "Epoch 342/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1788 - acc: 0.9618 - val_loss: 0.7141 - val_acc: 0.6937\n",
      "Epoch 343/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.1783 - acc: 0.9695 - val_loss: 0.7083 - val_acc: 0.6847\n",
      "Epoch 344/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1812 - acc: 0.9695 - val_loss: 0.7054 - val_acc: 0.6847\n",
      "Epoch 345/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1642 - acc: 0.9847 - val_loss: 0.7035 - val_acc: 0.6937\n",
      "Epoch 346/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1713 - acc: 0.9771 - val_loss: 0.7047 - val_acc: 0.6937\n",
      "Epoch 347/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1830 - acc: 0.9618 - val_loss: 0.7132 - val_acc: 0.7027\n",
      "Epoch 348/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1917 - acc: 0.9542 - val_loss: 0.7266 - val_acc: 0.7027\n",
      "Epoch 349/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1488 - acc: 0.9924 - val_loss: 0.7365 - val_acc: 0.7027\n",
      "Epoch 350/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1779 - acc: 0.9618 - val_loss: 0.7372 - val_acc: 0.7027\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.66530\n",
      "Epoch 351/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1597 - acc: 0.9695 - val_loss: 0.7281 - val_acc: 0.7027\n",
      "Epoch 352/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1740 - acc: 0.9542 - val_loss: 0.7144 - val_acc: 0.7117\n",
      "Epoch 353/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.1623 - acc: 0.9618 - val_loss: 0.7050 - val_acc: 0.6847\n",
      "Epoch 354/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1504 - acc: 0.9847 - val_loss: 0.7006 - val_acc: 0.6847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 355/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1663 - acc: 0.9771 - val_loss: 0.7003 - val_acc: 0.6847\n",
      "Epoch 356/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1639 - acc: 0.9847 - val_loss: 0.7050 - val_acc: 0.6847\n",
      "Epoch 357/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1461 - acc: 0.9924 - val_loss: 0.7164 - val_acc: 0.7117\n",
      "Epoch 358/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1526 - acc: 0.9847 - val_loss: 0.7354 - val_acc: 0.7027\n",
      "Epoch 359/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.1431 - acc: 0.9924 - val_loss: 0.7539 - val_acc: 0.6937\n",
      "Epoch 360/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1459 - acc: 0.9924 - val_loss: 0.7552 - val_acc: 0.6937\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.66530\n",
      "Epoch 361/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.1765 - acc: 0.9847 - val_loss: 0.7403 - val_acc: 0.7027\n",
      "Epoch 362/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1454 - acc: 0.9618 - val_loss: 0.7255 - val_acc: 0.7027\n",
      "Epoch 363/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.1598 - acc: 0.9695 - val_loss: 0.7125 - val_acc: 0.6937\n",
      "Epoch 364/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1532 - acc: 0.9695 - val_loss: 0.7073 - val_acc: 0.6847\n",
      "Epoch 365/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1648 - acc: 0.9695 - val_loss: 0.7072 - val_acc: 0.6847\n",
      "Epoch 366/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1628 - acc: 0.9771 - val_loss: 0.7105 - val_acc: 0.6847\n",
      "Epoch 367/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1625 - acc: 0.9695 - val_loss: 0.7188 - val_acc: 0.7117\n",
      "Epoch 368/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.1521 - acc: 0.9847 - val_loss: 0.7316 - val_acc: 0.7027\n",
      "Epoch 369/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1631 - acc: 0.9466 - val_loss: 0.7430 - val_acc: 0.7027\n",
      "Epoch 370/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1510 - acc: 0.9924 - val_loss: 0.7449 - val_acc: 0.7027\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.66530\n",
      "Epoch 371/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1526 - acc: 0.9695 - val_loss: 0.7423 - val_acc: 0.7027\n",
      "Epoch 372/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.1499 - acc: 0.9924 - val_loss: 0.7293 - val_acc: 0.7117\n",
      "Epoch 373/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1501 - acc: 0.9847 - val_loss: 0.7160 - val_acc: 0.6937\n",
      "Epoch 374/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.1383 - acc: 0.9847 - val_loss: 0.7109 - val_acc: 0.6847\n",
      "Epoch 375/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1443 - acc: 0.9847 - val_loss: 0.7108 - val_acc: 0.6937\n",
      "Epoch 376/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1496 - acc: 0.9771 - val_loss: 0.7145 - val_acc: 0.6937\n",
      "Epoch 377/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1281 - acc: 0.9847 - val_loss: 0.7206 - val_acc: 0.7117\n",
      "Epoch 378/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1337 - acc: 0.9847 - val_loss: 0.7266 - val_acc: 0.7117\n",
      "Epoch 379/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1543 - acc: 0.9695 - val_loss: 0.7316 - val_acc: 0.7117\n",
      "Epoch 380/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1351 - acc: 0.9847 - val_loss: 0.7303 - val_acc: 0.7117\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 0.66530\n",
      "Epoch 381/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1470 - acc: 0.9695 - val_loss: 0.7242 - val_acc: 0.7117\n",
      "Epoch 382/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1427 - acc: 0.9618 - val_loss: 0.7202 - val_acc: 0.7027\n",
      "Epoch 383/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1353 - acc: 0.9924 - val_loss: 0.7189 - val_acc: 0.6937\n",
      "Epoch 384/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1278 - acc: 0.9847 - val_loss: 0.7193 - val_acc: 0.6937\n",
      "Epoch 385/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1501 - acc: 0.9695 - val_loss: 0.7218 - val_acc: 0.7027\n",
      "Epoch 386/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1529 - acc: 0.9771 - val_loss: 0.7270 - val_acc: 0.7117\n",
      "Epoch 387/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1177 - acc: 1.0000 - val_loss: 0.7328 - val_acc: 0.7117\n",
      "Epoch 388/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1451 - acc: 0.9847 - val_loss: 0.7347 - val_acc: 0.7117\n",
      "Epoch 389/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1501 - acc: 0.9695 - val_loss: 0.7341 - val_acc: 0.7117\n",
      "Epoch 390/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1478 - acc: 0.9695 - val_loss: 0.7341 - val_acc: 0.7117\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.66530\n",
      "Epoch 391/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1238 - acc: 0.9924 - val_loss: 0.7352 - val_acc: 0.7117\n",
      "Epoch 392/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1340 - acc: 0.9847 - val_loss: 0.7326 - val_acc: 0.7117\n",
      "Epoch 393/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.1488 - acc: 0.9771 - val_loss: 0.7309 - val_acc: 0.7117\n",
      "Epoch 394/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1148 - acc: 0.9847 - val_loss: 0.7295 - val_acc: 0.7117\n",
      "Epoch 395/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1393 - acc: 0.9924 - val_loss: 0.7301 - val_acc: 0.7117\n",
      "Epoch 396/400\n",
      "131/131 [==============================] - 0s 4ms/step - loss: 0.1168 - acc: 1.0000 - val_loss: 0.7330 - val_acc: 0.7117\n",
      "Epoch 397/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1207 - acc: 0.9924 - val_loss: 0.7337 - val_acc: 0.7117\n",
      "Epoch 398/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1281 - acc: 0.9771 - val_loss: 0.7369 - val_acc: 0.7117\n",
      "Epoch 399/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1523 - acc: 0.9847 - val_loss: 0.7358 - val_acc: 0.7117\n",
      "Epoch 400/400\n",
      "131/131 [==============================] - 0s 3ms/step - loss: 0.1341 - acc: 0.9847 - val_loss: 0.7369 - val_acc: 0.7117\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.66530\n"
     ]
    }
   ],
   "source": [
    "remove_log_files('logs/')\n",
    "if USE_DATAGEN:\n",
    "    history = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=BATCH_SIZE), epochs=NB_EPOCH * 4, verbose=VERBOSE, validation_data=(X_valid, Y_valid), shuffle=True, callbacks=callbacks, steps_per_epoch=1)\n",
    "else:\n",
    "    history = model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=NB_EPOCH * 4, verbose=VERBOSE, validation_data=(X_valid, Y_valid), shuffle=True, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 1ms/step\n",
      "Test score: 0.9994901598624464\n",
      "Test acc: 0.5094339723856944\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=VERBOSE)\n",
    "print('Test score:', score[0])\n",
    "print('Test acc:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(121)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model acc')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig(IMG_PATH)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_dataのacc, lossは順調に推移するが、val_dataに対しては一定幅で同水準に留まる。\n",
    "元データが少ないから？(https://datascience.stackexchange.com/questions/37815/what-to-do-if-training-loss-decreases-but-validation-loss-does-not-decrease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_answers = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50,50))\n",
    "columns = 5\n",
    "cat_wrong_cnt = 0\n",
    "dog_wrong_cnt = 0\n",
    "for i, image in enumerate(X_test):\n",
    "    plt.subplot(len(X_test) / columns + 1, columns, i + 1)\n",
    "    predicted_num = predict_answers[i]\n",
    "    answer = y_test[i]\n",
    "    \n",
    "    if predicted_num != answer:\n",
    "        if predicted_num == 0:\n",
    "            label = 'cat'\n",
    "            cat_wrong_cnt += 1\n",
    "        else:\n",
    "            label = 'dog'\n",
    "            dog_wrong_cnt += 1\n",
    "        plt.title(label, fontsize=40)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(image)\n",
    "\n",
    "print('answer is dog, but cat is predicted:', cat_wrong_cnt)\n",
    "print('answer is cat, but dog is predicted:', dog_wrong_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像加工 min val-loss, filters, dropout, note<br>\n",
    "gray 0.69, 16, 0.3, epoch50くらいで過学習<br>\n",
    "color 0.59, 16, 0.3, epoch180くらいで過学習<br>\n",
    "aug, 0.61, 16, 0.3, epoch180くらいで過学習<br>\n",
    "gray & aug<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
