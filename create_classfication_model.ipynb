{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 X_train amount\n",
      "111 X_valid amount\n",
      "53 X_test amount\n",
      "(131, 64, 64) X_train shape\n",
      "(111, 64, 64) X_valid shape\n",
      "(53, 64, 64) X_test shape\n",
      "(64, 64, 1) shape\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import  Conv1D, Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam\n",
    "from matplotlib import pyplot as plt\n",
    "import keras\n",
    "import keras.callbacks as KC\n",
    "\n",
    "cat_dir = 'clean_images/cat_images/'\n",
    "dog_dir = 'clean_images/dog_images/'\n",
    "SIZE = 64 #100から変更\n",
    "TRAIN_RATIO = 0.8\n",
    "RESHAPED = 0\n",
    "NB_CLASSES = 2\n",
    "OPTIMIZER = SGD()\n",
    "BATCH_SIZE = 131\n",
    "NB_EPOCH = 100\n",
    "VALIDATION_SPLIT = 0.4\n",
    "VERBOSE = 1\n",
    "SAVED_MODEL_PATH = 'models/cat_dog_classfication_aug_gray_model.hdf5'\n",
    "COLOR_MODE = 0\n",
    "USE_DATAGEN = True\n",
    "\n",
    "def prepare_data():\n",
    "    # 猫(0)と犬(1)の画像を取得してフラグを追加したにシャッフル加工してデータとして返す。\n",
    "    \n",
    "    images = []\n",
    "    cat_answers = []\n",
    "    dog_answers = []\n",
    "    cat_images = []\n",
    "    dog_images = []\n",
    "    validation_images = []\n",
    "    validation_answers = []\n",
    "\n",
    "    cat_files = glob.glob(os.path.join(cat_dir, '*.jpg'))\n",
    "    cat_files.sort()\n",
    "    dog_files = glob.glob(os.path.join(dog_dir, '*.jpg'))\n",
    "    dog_files.sort()\n",
    "\n",
    "    for cat_image in cat_files:\n",
    "        if cat_image.endswith('.jpg'):\n",
    "            cat_images.append(resize_for_model(cv2.imread(cat_image, COLOR_MODE)))\n",
    "            cat_answers.append(0)\n",
    "\n",
    "    for dog_image in dog_files:\n",
    "        if dog_image.endswith('.jpg'):\n",
    "            dog_images.append(resize_for_model(cv2.imread(dog_image, COLOR_MODE)))\n",
    "            dog_answers.append(1)\n",
    "\n",
    "    test_border_cat = int(len(cat_images) * (1 - TRAIN_RATIO))\n",
    "    test_border_dog = int(len(dog_images) * (1 - TRAIN_RATIO))\n",
    "    \n",
    "    test_images = np.array(cat_images[:test_border_cat] + dog_images[:test_border_dog])\n",
    "    test_answers = np.array(cat_answers[:test_border_cat] + dog_answers[:test_border_dog])\n",
    "            \n",
    "    validation_border_cat = test_border_cat + int(len(cat_images) * TRAIN_RATIO * VALIDATION_SPLIT)\n",
    "    validation_border_dog = test_border_dog + int(len(dog_images) * TRAIN_RATIO * VALIDATION_SPLIT)\n",
    "\n",
    "    validation_images = np.array(cat_images[test_border_cat:test_border_cat + validation_border_cat] + dog_images[test_border_dog:validation_border_dog])\n",
    "    validation_answers = np.array(cat_answers[test_border_cat:test_border_cat + validation_border_cat] + dog_answers[test_border_dog:validation_border_dog])\n",
    "    train_images = np.array(cat_images[validation_border_cat:] + dog_images[validation_border_dog:])\n",
    "    train_answers = np.array(cat_answers[validation_border_cat:] + dog_answers[validation_border_dog:])\n",
    "\n",
    "    # imagesとanswersの関係保ったままシャッフル\n",
    "    data = []\n",
    "    for images, answers in ((train_images, train_answers), (validation_images, validation_answers), (test_images, test_answers)):\n",
    "        random_idxs = np.random.permutation(len(images))\n",
    "        images = images[random_idxs]\n",
    "        answers = answers[random_idxs]\n",
    "        data.append([images, answers])\n",
    "    \n",
    "    return (data[0][0], data[0][1]), (data[1][0], data[1][1]), (data[2][0], data[2][1])\n",
    "\n",
    "def resize_for_model(image):\n",
    "    # np形式のimageを特定の大きさにresizeする。\n",
    "    return cv2.resize(image, (SIZE, SIZE))\n",
    "\n",
    "def remove_log_files(dir):\n",
    "    files = glob.glob(os.path.join(dir, '*.local'))\n",
    "    for file in files:\n",
    "        os.remove(file)\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    (X_train, y_train),(X_valid, y_valid), (X_test, y_test) = prepare_data()\n",
    "    print(len(X_train), 'X_train amount')\n",
    "    print(len(X_valid), 'X_valid amount')    \n",
    "    print(len(X_test), 'X_test amount')\n",
    "    print(X_train.shape, 'X_train shape')\n",
    "    print(X_valid.shape, 'X_valid shape')    \n",
    "    print(X_test.shape, 'X_test shape')\n",
    "    if len(X_train.shape) > 3:\n",
    "        SHAPE = (X_train.shape[1], X_train.shape[2], X_train.shape[3])\n",
    "    else:\n",
    "        SHAPE = (X_train.shape[1], X_train.shape[2], 1)\n",
    "    print(SHAPE, 'shape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHAPE[2] == 1:\n",
    "    X_train = X_train.reshape(X_train.shape[0],  SIZE, SIZE, 1)\n",
    "    X_valid = X_valid.reshape(X_valid.shape[0],  SIZE, SIZE, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0],  SIZE, SIZE, 1)\n",
    "\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_valid = X_valid.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_valid /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_valid = np_utils.to_categorical(y_valid, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [KC.TensorBoard()\n",
    "                     ,KC.ModelCheckpoint(filepath=SAVED_MODEL_PATH,\n",
    "                                                           verbose=1,\n",
    "                                                           save_weights_only=True,\n",
    "                                                           save_best_only=True,\n",
    "                                                           period=10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image  import ImageDataGenerator\n",
    "\n",
    "if USE_DATAGEN:\n",
    "    datagen = ImageDataGenerator(featurewise_center=True,\n",
    "                                                            featurewise_std_normalization=True,\n",
    "                                                            rotation_range=20,\n",
    "                                                            width_shift_range=0.2,\n",
    "                                                            height_shift_range=0.2,\n",
    "                                                            horizontal_flip=True)\n",
    "\n",
    "    datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#参考: https://keras.io/getting-started/sequential-model-guide/\n",
    "model = Sequential()\n",
    "# input: 100x100 images with 3 channels -> (100, 100, 3) tensors. 64の方が良さげ\n",
    "FILTERS = 16\n",
    "# with 3 channels\n",
    "model.add(Conv2D(FILTERS, (3, 3), activation='relu', input_shape=SHAPE))\n",
    "model.add(Conv2D(FILTERS, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "#この層無い方がマシっぽい\n",
    "# model.add(Conv2D(UNITS * 2, (3, 3), activation='relu'))\n",
    "# model.add(Conv2D(UNITS * 2, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dropout(0.6)) #無い方が良い\n",
    "model.add(Dense(NB_CLASSES, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "1/1 [==============================] - 1s 992ms/step - loss: 0.7122 - acc: 0.4962 - val_loss: 0.7044 - val_acc: 0.3604\n",
      "Epoch 2/400\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 0.6951 - acc: 0.5038 - val_loss: 0.6974 - val_acc: 0.4324\n",
      "Epoch 3/400\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 0.6973 - acc: 0.5267 - val_loss: 0.6936 - val_acc: 0.4775\n",
      "Epoch 4/400\n",
      "1/1 [==============================] - 1s 513ms/step - loss: 0.7012 - acc: 0.4504 - val_loss: 0.6917 - val_acc: 0.5495\n",
      "Epoch 5/400\n",
      "1/1 [==============================] - 1s 501ms/step - loss: 0.7041 - acc: 0.4809 - val_loss: 0.6915 - val_acc: 0.5676\n",
      "Epoch 6/400\n",
      "1/1 [==============================] - 0s 488ms/step - loss: 0.7023 - acc: 0.4809 - val_loss: 0.6921 - val_acc: 0.5405\n",
      "Epoch 7/400\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 0.6930 - acc: 0.5115 - val_loss: 0.6928 - val_acc: 0.5405\n",
      "Epoch 8/400\n",
      "1/1 [==============================] - 0s 485ms/step - loss: 0.6946 - acc: 0.5038 - val_loss: 0.6928 - val_acc: 0.5225\n",
      "Epoch 9/400\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 0.6847 - acc: 0.5725 - val_loss: 0.6919 - val_acc: 0.5405\n",
      "Epoch 10/400\n",
      "1/1 [==============================] - 0s 472ms/step - loss: 0.6694 - acc: 0.6183 - val_loss: 0.6906 - val_acc: 0.5946\n",
      "\n",
      "Epoch 00010: val_loss improved from inf to 0.69057, saving model to models/cat_dog_classfication_aug_gray_model.hdf5\n",
      "Epoch 11/400\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 0.6788 - acc: 0.5802 - val_loss: 0.6887 - val_acc: 0.5586\n",
      "Epoch 12/400\n",
      "1/1 [==============================] - 1s 511ms/step - loss: 0.6683 - acc: 0.5725 - val_loss: 0.6869 - val_acc: 0.5766\n",
      "Epoch 13/400\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 0.6696 - acc: 0.6336 - val_loss: 0.6852 - val_acc: 0.5676\n",
      "Epoch 14/400\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 0.6732 - acc: 0.6107 - val_loss: 0.6835 - val_acc: 0.5766\n",
      "Epoch 15/400\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 0.6757 - acc: 0.5573 - val_loss: 0.6821 - val_acc: 0.5856\n",
      "Epoch 16/400\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 0.6825 - acc: 0.5573 - val_loss: 0.6806 - val_acc: 0.6036\n",
      "Epoch 17/400\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 0.6698 - acc: 0.5573 - val_loss: 0.6791 - val_acc: 0.6126\n",
      "Epoch 18/400\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 0.6691 - acc: 0.5725 - val_loss: 0.6779 - val_acc: 0.6216\n",
      "Epoch 19/400\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 0.6732 - acc: 0.5954 - val_loss: 0.6769 - val_acc: 0.6306\n",
      "Epoch 20/400\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 0.6814 - acc: 0.5420 - val_loss: 0.6761 - val_acc: 0.6216\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.69057 to 0.67613, saving model to models/cat_dog_classfication_aug_gray_model.hdf5\n",
      "Epoch 21/400\n",
      "1/1 [==============================] - 0s 477ms/step - loss: 0.6668 - acc: 0.5878 - val_loss: 0.6756 - val_acc: 0.6216\n",
      "Epoch 22/400\n",
      "1/1 [==============================] - 0s 497ms/step - loss: 0.6724 - acc: 0.5878 - val_loss: 0.6753 - val_acc: 0.6126\n",
      "Epoch 23/400\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 0.6537 - acc: 0.6489 - val_loss: 0.6754 - val_acc: 0.6036\n",
      "Epoch 24/400\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 0.6884 - acc: 0.5344 - val_loss: 0.6757 - val_acc: 0.6126\n",
      "Epoch 25/400\n",
      "1/1 [==============================] - 0s 493ms/step - loss: 0.6666 - acc: 0.6031 - val_loss: 0.6759 - val_acc: 0.6126\n",
      "Epoch 26/400\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 0.6666 - acc: 0.5573 - val_loss: 0.6759 - val_acc: 0.6126\n",
      "Epoch 27/400\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 0.6741 - acc: 0.5725 - val_loss: 0.6758 - val_acc: 0.6126\n",
      "Epoch 28/400\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 0.6492 - acc: 0.6260 - val_loss: 0.6757 - val_acc: 0.6036\n",
      "Epoch 29/400\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 0.6706 - acc: 0.5649 - val_loss: 0.6757 - val_acc: 0.6036\n",
      "Epoch 30/400\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 0.6382 - acc: 0.6336 - val_loss: 0.6758 - val_acc: 0.6036\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.67613 to 0.67583, saving model to models/cat_dog_classfication_aug_gray_model.hdf5\n",
      "Epoch 31/400\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 0.6606 - acc: 0.6260 - val_loss: 0.6758 - val_acc: 0.6126\n",
      "Epoch 32/400\n",
      "1/1 [==============================] - 0s 490ms/step - loss: 0.6353 - acc: 0.6031 - val_loss: 0.6758 - val_acc: 0.6036\n",
      "Epoch 33/400\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 0.6450 - acc: 0.6336 - val_loss: 0.6756 - val_acc: 0.6126\n",
      "Epoch 34/400\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 0.6568 - acc: 0.6336 - val_loss: 0.6751 - val_acc: 0.6216\n",
      "Epoch 35/400\n",
      "1/1 [==============================] - 0s 487ms/step - loss: 0.6649 - acc: 0.6031 - val_loss: 0.6746 - val_acc: 0.6216\n",
      "Epoch 36/400\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 0.6338 - acc: 0.6260 - val_loss: 0.6742 - val_acc: 0.6216\n",
      "Epoch 37/400\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 0.6576 - acc: 0.6183 - val_loss: 0.6737 - val_acc: 0.6216\n",
      "Epoch 38/400\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 0.6617 - acc: 0.5496 - val_loss: 0.6731 - val_acc: 0.6126\n",
      "Epoch 39/400\n",
      "1/1 [==============================] - 0s 498ms/step - loss: 0.6601 - acc: 0.6107 - val_loss: 0.6724 - val_acc: 0.6126\n",
      "Epoch 40/400\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 0.6322 - acc: 0.6870 - val_loss: 0.6718 - val_acc: 0.6126\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.67583 to 0.67176, saving model to models/cat_dog_classfication_aug_gray_model.hdf5\n",
      "Epoch 41/400\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 0.6508 - acc: 0.6260 - val_loss: 0.6712 - val_acc: 0.6126\n",
      "Epoch 42/400\n",
      "1/1 [==============================] - 0s 491ms/step - loss: 0.6617 - acc: 0.6489 - val_loss: 0.6708 - val_acc: 0.6126\n",
      "Epoch 43/400\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 0.6543 - acc: 0.5649 - val_loss: 0.6706 - val_acc: 0.6126\n",
      "Epoch 44/400\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 0.6375 - acc: 0.6718 - val_loss: 0.6703 - val_acc: 0.6126\n",
      "Epoch 45/400\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 0.6495 - acc: 0.6336 - val_loss: 0.6704 - val_acc: 0.6036\n",
      "Epoch 46/400\n",
      "1/1 [==============================] - 1s 561ms/step - loss: 0.6427 - acc: 0.6183 - val_loss: 0.6704 - val_acc: 0.6036\n",
      "Epoch 47/400\n",
      "1/1 [==============================] - 0s 480ms/step - loss: 0.6531 - acc: 0.5954 - val_loss: 0.6704 - val_acc: 0.6036\n",
      "Epoch 48/400\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 0.6403 - acc: 0.6489 - val_loss: 0.6706 - val_acc: 0.6036\n",
      "Epoch 49/400\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 0.6277 - acc: 0.6947 - val_loss: 0.6708 - val_acc: 0.5946\n",
      "Epoch 50/400\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 0.6606 - acc: 0.5649 - val_loss: 0.6709 - val_acc: 0.5946\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.67176 to 0.67094, saving model to models/cat_dog_classfication_aug_gray_model.hdf5\n",
      "Epoch 51/400\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 0.6435 - acc: 0.6183 - val_loss: 0.6709 - val_acc: 0.5856\n",
      "Epoch 52/400\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 0.6430 - acc: 0.6260 - val_loss: 0.6707 - val_acc: 0.5946\n",
      "Epoch 53/400\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 0.6478 - acc: 0.6260 - val_loss: 0.6701 - val_acc: 0.5946\n",
      "Epoch 54/400\n",
      "1/1 [==============================] - 0s 479ms/step - loss: 0.6362 - acc: 0.6565 - val_loss: 0.6699 - val_acc: 0.5946\n",
      "Epoch 55/400\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 0.6309 - acc: 0.6565 - val_loss: 0.6697 - val_acc: 0.5946\n",
      "Epoch 56/400\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 0.6473 - acc: 0.6260 - val_loss: 0.6696 - val_acc: 0.5946\n",
      "Epoch 57/400\n",
      "1/1 [==============================] - 0s 434ms/step - loss: 0.6041 - acc: 0.6641 - val_loss: 0.6699 - val_acc: 0.5946\n",
      "Epoch 58/400\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 0.6428 - acc: 0.5954 - val_loss: 0.6700 - val_acc: 0.5946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/400\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 0.6506 - acc: 0.6336 - val_loss: 0.6701 - val_acc: 0.5946\n",
      "Epoch 60/400\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 0.6308 - acc: 0.6489 - val_loss: 0.6701 - val_acc: 0.5856\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.67094 to 0.67011, saving model to models/cat_dog_classfication_aug_gray_model.hdf5\n",
      "Epoch 61/400\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 0.6443 - acc: 0.5878 - val_loss: 0.6699 - val_acc: 0.5856\n",
      "Epoch 62/400\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 0.6237 - acc: 0.6336 - val_loss: 0.6690 - val_acc: 0.5946\n",
      "Epoch 63/400\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 0.6425 - acc: 0.5878 - val_loss: 0.6679 - val_acc: 0.5946\n",
      "Epoch 64/400\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 0.6375 - acc: 0.6641 - val_loss: 0.6667 - val_acc: 0.6036\n",
      "Epoch 65/400\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.6382 - acc: 0.6489 - val_loss: 0.6656 - val_acc: 0.5946\n",
      "Epoch 66/400\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 0.6363 - acc: 0.7176 - val_loss: 0.6646 - val_acc: 0.6036\n",
      "Epoch 67/400\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 0.6100 - acc: 0.6641 - val_loss: 0.6640 - val_acc: 0.6036\n",
      "Epoch 68/400\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 0.6362 - acc: 0.6412 - val_loss: 0.6637 - val_acc: 0.6036\n",
      "Epoch 69/400\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 0.6321 - acc: 0.6183 - val_loss: 0.6635 - val_acc: 0.6036\n",
      "Epoch 70/400\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 0.6593 - acc: 0.5573 - val_loss: 0.6634 - val_acc: 0.6036\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.67011 to 0.66343, saving model to models/cat_dog_classfication_aug_gray_model.hdf5\n",
      "Epoch 71/400\n",
      "1/1 [==============================] - 0s 484ms/step - loss: 0.6197 - acc: 0.6412 - val_loss: 0.6632 - val_acc: 0.6036\n",
      "Epoch 72/400\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 0.6190 - acc: 0.6718 - val_loss: 0.6630 - val_acc: 0.6036\n",
      "Epoch 73/400\n",
      "1/1 [==============================] - 0s 481ms/step - loss: 0.6456 - acc: 0.5802 - val_loss: 0.6626 - val_acc: 0.6036\n",
      "Epoch 74/400\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 0.6118 - acc: 0.6870 - val_loss: 0.6624 - val_acc: 0.6036\n",
      "Epoch 75/400\n",
      "1/1 [==============================] - 0s 487ms/step - loss: 0.6541 - acc: 0.6183 - val_loss: 0.6621 - val_acc: 0.6036\n",
      "Epoch 76/400\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 0.6172 - acc: 0.6641 - val_loss: 0.6619 - val_acc: 0.6036\n",
      "Epoch 77/400\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 0.6115 - acc: 0.6489 - val_loss: 0.6621 - val_acc: 0.6036\n",
      "Epoch 78/400\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 0.6046 - acc: 0.6870 - val_loss: 0.6626 - val_acc: 0.5946\n",
      "Epoch 79/400\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 0.5965 - acc: 0.6489 - val_loss: 0.6633 - val_acc: 0.6036\n",
      "Epoch 80/400\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 0.6425 - acc: 0.6260 - val_loss: 0.6639 - val_acc: 0.5856\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.66343\n",
      "Epoch 81/400\n",
      "1/1 [==============================] - 0s 484ms/step - loss: 0.6168 - acc: 0.6412 - val_loss: 0.6639 - val_acc: 0.5856\n",
      "Epoch 82/400\n",
      "1/1 [==============================] - 0s 489ms/step - loss: 0.6003 - acc: 0.6641 - val_loss: 0.6637 - val_acc: 0.5856\n",
      "Epoch 83/400\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 0.6357 - acc: 0.6718 - val_loss: 0.6632 - val_acc: 0.5856\n",
      "Epoch 84/400\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.6365 - acc: 0.6412 - val_loss: 0.6627 - val_acc: 0.6036\n",
      "Epoch 85/400\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 0.6479 - acc: 0.5954 - val_loss: 0.6624 - val_acc: 0.6036\n",
      "Epoch 86/400\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 0.6423 - acc: 0.6336 - val_loss: 0.6619 - val_acc: 0.6036\n",
      "Epoch 87/400\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 0.6196 - acc: 0.6641 - val_loss: 0.6619 - val_acc: 0.6036\n",
      "Epoch 88/400\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.6350 - acc: 0.6260 - val_loss: 0.6618 - val_acc: 0.6036\n",
      "Epoch 89/400\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.6473 - acc: 0.6031 - val_loss: 0.6620 - val_acc: 0.6036\n",
      "Epoch 90/400\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 0.6033 - acc: 0.7099 - val_loss: 0.6622 - val_acc: 0.6036\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.66343 to 0.66224, saving model to models/cat_dog_classfication_aug_gray_model.hdf5\n",
      "Epoch 91/400\n",
      "1/1 [==============================] - 1s 539ms/step - loss: 0.5944 - acc: 0.6718 - val_loss: 0.6628 - val_acc: 0.5856\n",
      "Epoch 92/400\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 0.6288 - acc: 0.6183 - val_loss: 0.6637 - val_acc: 0.5946\n",
      "Epoch 93/400\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 0.6300 - acc: 0.6412 - val_loss: 0.6644 - val_acc: 0.5946\n",
      "Epoch 94/400\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 0.6275 - acc: 0.6412 - val_loss: 0.6646 - val_acc: 0.5856\n",
      "Epoch 95/400\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 0.6152 - acc: 0.6870 - val_loss: 0.6647 - val_acc: 0.5856\n",
      "Epoch 96/400\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 0.6366 - acc: 0.6183 - val_loss: 0.6645 - val_acc: 0.5856\n",
      "Epoch 97/400\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 0.6291 - acc: 0.6260 - val_loss: 0.6640 - val_acc: 0.5946\n",
      "Epoch 98/400\n",
      "1/1 [==============================] - 0s 498ms/step - loss: 0.6249 - acc: 0.6183 - val_loss: 0.6631 - val_acc: 0.5946\n",
      "Epoch 99/400\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 0.6117 - acc: 0.7252 - val_loss: 0.6624 - val_acc: 0.5946\n",
      "Epoch 100/400\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 0.6103 - acc: 0.6183 - val_loss: 0.6620 - val_acc: 0.5856\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.66224 to 0.66200, saving model to models/cat_dog_classfication_aug_gray_model.hdf5\n",
      "Epoch 101/400\n",
      "1/1 [==============================] - 0s 495ms/step - loss: 0.6266 - acc: 0.6183 - val_loss: 0.6618 - val_acc: 0.5856\n",
      "Epoch 102/400\n",
      "1/1 [==============================] - 0s 484ms/step - loss: 0.6089 - acc: 0.6870 - val_loss: 0.6620 - val_acc: 0.5856\n",
      "Epoch 103/400\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.6539 - acc: 0.6031 - val_loss: 0.6622 - val_acc: 0.5856\n",
      "Epoch 104/400\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 0.6227 - acc: 0.6336 - val_loss: 0.6626 - val_acc: 0.6036\n",
      "Epoch 105/400\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 0.6138 - acc: 0.6565 - val_loss: 0.6625 - val_acc: 0.6036\n",
      "Epoch 106/400\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.6245 - acc: 0.6794 - val_loss: 0.6625 - val_acc: 0.6036\n",
      "Epoch 107/400\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.6136 - acc: 0.6718 - val_loss: 0.6624 - val_acc: 0.6036\n",
      "Epoch 108/400\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.5884 - acc: 0.6641 - val_loss: 0.6627 - val_acc: 0.6036\n",
      "Epoch 109/400\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 0.6199 - acc: 0.6565 - val_loss: 0.6628 - val_acc: 0.6036\n",
      "Epoch 110/400\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 0.6318 - acc: 0.6565 - val_loss: 0.6630 - val_acc: 0.6036\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.66200\n",
      "Epoch 111/400\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 0.6202 - acc: 0.6718 - val_loss: 0.6635 - val_acc: 0.6216\n",
      "Epoch 112/400\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 0.6429 - acc: 0.6107 - val_loss: 0.6633 - val_acc: 0.6216\n",
      "Epoch 113/400\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 0.5745 - acc: 0.6870 - val_loss: 0.6633 - val_acc: 0.6216\n",
      "Epoch 114/400\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.6302 - acc: 0.6412 - val_loss: 0.6632 - val_acc: 0.6216\n",
      "Epoch 115/400\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.6145 - acc: 0.6336 - val_loss: 0.6635 - val_acc: 0.6216\n",
      "Epoch 116/400\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.6021 - acc: 0.6947 - val_loss: 0.6638 - val_acc: 0.6126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/400\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 0.6127 - acc: 0.6718 - val_loss: 0.6638 - val_acc: 0.6126\n",
      "Epoch 118/400\n",
      "1/1 [==============================] - 0s 436ms/step - loss: 0.6183 - acc: 0.6947 - val_loss: 0.6635 - val_acc: 0.6306\n",
      "Epoch 119/400\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.6154 - acc: 0.6336 - val_loss: 0.6627 - val_acc: 0.6216\n",
      "Epoch 120/400\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 0.6335 - acc: 0.6641 - val_loss: 0.6614 - val_acc: 0.5946\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.66200 to 0.66138, saving model to models/cat_dog_classfication_aug_gray_model.hdf5\n",
      "Epoch 121/400\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 0.6035 - acc: 0.7023 - val_loss: 0.6605 - val_acc: 0.6036\n",
      "Epoch 122/400\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.6364 - acc: 0.6031 - val_loss: 0.6600 - val_acc: 0.6126\n",
      "Epoch 123/400\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 0.6243 - acc: 0.6641 - val_loss: 0.6601 - val_acc: 0.6036\n",
      "Epoch 124/400\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 0.6144 - acc: 0.6718 - val_loss: 0.6602 - val_acc: 0.6036\n",
      "Epoch 125/400\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 0.6005 - acc: 0.6794 - val_loss: 0.6604 - val_acc: 0.6036\n",
      "Epoch 126/400\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.6295 - acc: 0.6412 - val_loss: 0.6606 - val_acc: 0.5946\n",
      "Epoch 127/400\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 0.5824 - acc: 0.7405 - val_loss: 0.6606 - val_acc: 0.5946\n",
      "Epoch 128/400\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 0.6177 - acc: 0.6794 - val_loss: 0.6606 - val_acc: 0.5946\n",
      "Epoch 129/400\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 0.6181 - acc: 0.6718 - val_loss: 0.6604 - val_acc: 0.6036\n",
      "Epoch 130/400\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.5794 - acc: 0.7252 - val_loss: 0.6604 - val_acc: 0.6036\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.66138 to 0.66039, saving model to models/cat_dog_classfication_aug_gray_model.hdf5\n",
      "Epoch 131/400\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 0.5950 - acc: 0.6870 - val_loss: 0.6602 - val_acc: 0.6036\n",
      "Epoch 132/400\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 0.6051 - acc: 0.7176 - val_loss: 0.6601 - val_acc: 0.6036\n",
      "Epoch 133/400\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 0.5836 - acc: 0.6794 - val_loss: 0.6603 - val_acc: 0.6126\n",
      "Epoch 134/400\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.6333 - acc: 0.6412 - val_loss: 0.6605 - val_acc: 0.6036\n",
      "Epoch 135/400\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 0.6096 - acc: 0.6947 - val_loss: 0.6608 - val_acc: 0.6126\n",
      "Epoch 136/400\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 0.6231 - acc: 0.6336 - val_loss: 0.6613 - val_acc: 0.6216\n",
      "Epoch 137/400\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 0.6099 - acc: 0.6947 - val_loss: 0.6617 - val_acc: 0.6216\n",
      "Epoch 138/400\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 0.6229 - acc: 0.6336 - val_loss: 0.6620 - val_acc: 0.6216\n",
      "Epoch 139/400\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 0.6211 - acc: 0.6870 - val_loss: 0.6617 - val_acc: 0.6216\n",
      "Epoch 140/400\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 0.6032 - acc: 0.6641 - val_loss: 0.6617 - val_acc: 0.6216\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.66039\n",
      "Epoch 141/400\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 0.6370 - acc: 0.6107 - val_loss: 0.6616 - val_acc: 0.6216\n",
      "Epoch 142/400\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 0.5962 - acc: 0.6718 - val_loss: 0.6614 - val_acc: 0.6126\n",
      "Epoch 143/400\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 0.6082 - acc: 0.6794 - val_loss: 0.6613 - val_acc: 0.6126\n",
      "Epoch 144/400\n",
      "1/1 [==============================] - 0s 440ms/step - loss: 0.6124 - acc: 0.6794 - val_loss: 0.6614 - val_acc: 0.6126\n",
      "Epoch 145/400\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 0.6290 - acc: 0.6870 - val_loss: 0.6615 - val_acc: 0.6126\n",
      "Epoch 146/400\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 0.6404 - acc: 0.6336 - val_loss: 0.6619 - val_acc: 0.6216\n",
      "Epoch 147/400\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.5991 - acc: 0.6641 - val_loss: 0.6624 - val_acc: 0.6126\n",
      "Epoch 148/400\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 0.5996 - acc: 0.6870 - val_loss: 0.6630 - val_acc: 0.6216\n",
      "Epoch 149/400\n",
      "1/1 [==============================] - 0s 495ms/step - loss: 0.5760 - acc: 0.7099 - val_loss: 0.6634 - val_acc: 0.6216\n",
      "Epoch 150/400\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 0.6423 - acc: 0.6489 - val_loss: 0.6633 - val_acc: 0.6216\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.66039\n",
      "Epoch 151/400\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 0.6015 - acc: 0.6870 - val_loss: 0.6632 - val_acc: 0.6126\n",
      "Epoch 152/400\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 0.5566 - acc: 0.7328 - val_loss: 0.6628 - val_acc: 0.6036\n",
      "Epoch 153/400\n",
      "1/1 [==============================] - 0s 472ms/step - loss: 0.6151 - acc: 0.6336 - val_loss: 0.6622 - val_acc: 0.6036\n",
      "Epoch 154/400\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 0.6103 - acc: 0.6794 - val_loss: 0.6615 - val_acc: 0.6126\n",
      "Epoch 155/400\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 0.6023 - acc: 0.6412 - val_loss: 0.6609 - val_acc: 0.6036\n",
      "Epoch 156/400\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 0.5808 - acc: 0.7023 - val_loss: 0.6607 - val_acc: 0.6036\n",
      "Epoch 157/400\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 0.6251 - acc: 0.6489 - val_loss: 0.6611 - val_acc: 0.6036\n",
      "Epoch 158/400\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 0.6008 - acc: 0.6565 - val_loss: 0.6618 - val_acc: 0.5946\n",
      "Epoch 159/400\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.6130 - acc: 0.6641 - val_loss: 0.6622 - val_acc: 0.5946\n",
      "Epoch 160/400\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 0.6196 - acc: 0.7099 - val_loss: 0.6623 - val_acc: 0.5946\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.66039\n",
      "Epoch 161/400\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 0.5631 - acc: 0.7405 - val_loss: 0.6620 - val_acc: 0.5946\n",
      "Epoch 162/400\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.5915 - acc: 0.6565 - val_loss: 0.6616 - val_acc: 0.5946\n",
      "Epoch 163/400\n",
      "1/1 [==============================] - 1s 523ms/step - loss: 0.5845 - acc: 0.7099 - val_loss: 0.6616 - val_acc: 0.5946\n",
      "Epoch 164/400\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 0.6386 - acc: 0.6412 - val_loss: 0.6618 - val_acc: 0.5946\n",
      "Epoch 165/400\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 0.5729 - acc: 0.7023 - val_loss: 0.6621 - val_acc: 0.5946\n",
      "Epoch 166/400\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.6242 - acc: 0.6489 - val_loss: 0.6628 - val_acc: 0.6036\n",
      "Epoch 167/400\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 0.5712 - acc: 0.7557 - val_loss: 0.6633 - val_acc: 0.6036\n",
      "Epoch 168/400\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 0.6807 - acc: 0.6260 - val_loss: 0.6637 - val_acc: 0.5766\n",
      "Epoch 169/400\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 0.6066 - acc: 0.7176 - val_loss: 0.6640 - val_acc: 0.5856\n",
      "Epoch 170/400\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 0.6075 - acc: 0.6947 - val_loss: 0.6643 - val_acc: 0.5856\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.66039\n",
      "Epoch 171/400\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.5831 - acc: 0.6947 - val_loss: 0.6640 - val_acc: 0.5856\n",
      "Epoch 172/400\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 0.5998 - acc: 0.6947 - val_loss: 0.6633 - val_acc: 0.5856\n",
      "Epoch 173/400\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 0.5594 - acc: 0.6947 - val_loss: 0.6625 - val_acc: 0.5946\n",
      "Epoch 174/400\n",
      "1/1 [==============================] - 0s 472ms/step - loss: 0.5834 - acc: 0.7023 - val_loss: 0.6620 - val_acc: 0.5946\n",
      "Epoch 175/400\n",
      "1/1 [==============================] - 1s 540ms/step - loss: 0.5906 - acc: 0.6794 - val_loss: 0.6614 - val_acc: 0.5946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176/400\n",
      "1/1 [==============================] - 1s 501ms/step - loss: 0.5869 - acc: 0.7023 - val_loss: 0.6611 - val_acc: 0.5856\n",
      "Epoch 177/400\n",
      "1/1 [==============================] - 0s 484ms/step - loss: 0.6283 - acc: 0.6489 - val_loss: 0.6611 - val_acc: 0.5946\n",
      "Epoch 178/400\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 0.5982 - acc: 0.6870 - val_loss: 0.6614 - val_acc: 0.5946\n",
      "Epoch 179/400\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 0.5676 - acc: 0.7023 - val_loss: 0.6623 - val_acc: 0.5946\n",
      "Epoch 180/400\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 0.6196 - acc: 0.6260 - val_loss: 0.6633 - val_acc: 0.5856\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.66039\n",
      "Epoch 181/400\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 0.6382 - acc: 0.6718 - val_loss: 0.6644 - val_acc: 0.5766\n",
      "Epoch 182/400\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 0.6185 - acc: 0.7023 - val_loss: 0.6649 - val_acc: 0.5856\n",
      "Epoch 183/400\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 0.6220 - acc: 0.7023 - val_loss: 0.6645 - val_acc: 0.5856\n",
      "Epoch 184/400\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 0.5964 - acc: 0.7023 - val_loss: 0.6632 - val_acc: 0.5856\n",
      "Epoch 185/400\n",
      "1/1 [==============================] - 0s 482ms/step - loss: 0.6262 - acc: 0.6641 - val_loss: 0.6616 - val_acc: 0.5856\n",
      "Epoch 186/400\n",
      "1/1 [==============================] - 1s 522ms/step - loss: 0.6194 - acc: 0.6107 - val_loss: 0.6603 - val_acc: 0.6036\n",
      "Epoch 187/400\n",
      "1/1 [==============================] - 0s 477ms/step - loss: 0.5612 - acc: 0.6947 - val_loss: 0.6592 - val_acc: 0.6036\n",
      "Epoch 188/400\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 0.6236 - acc: 0.6794 - val_loss: 0.6587 - val_acc: 0.5946\n",
      "Epoch 189/400\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 0.6478 - acc: 0.6336 - val_loss: 0.6586 - val_acc: 0.6036\n",
      "Epoch 190/400\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 0.6032 - acc: 0.7099 - val_loss: 0.6588 - val_acc: 0.6036\n",
      "\n",
      "Epoch 00190: val_loss improved from 0.66039 to 0.65876, saving model to models/cat_dog_classfication_aug_gray_model.hdf5\n",
      "Epoch 191/400\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 0.6320 - acc: 0.6412 - val_loss: 0.6592 - val_acc: 0.6036\n",
      "Epoch 192/400\n",
      "1/1 [==============================] - 1s 541ms/step - loss: 0.5817 - acc: 0.7252 - val_loss: 0.6596 - val_acc: 0.6036\n",
      "Epoch 193/400\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 0.6034 - acc: 0.6718 - val_loss: 0.6601 - val_acc: 0.6036\n",
      "Epoch 194/400\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 0.6240 - acc: 0.6565 - val_loss: 0.6606 - val_acc: 0.5946\n",
      "Epoch 195/400\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 0.6114 - acc: 0.6794 - val_loss: 0.6608 - val_acc: 0.5946\n",
      "Epoch 196/400\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 0.6100 - acc: 0.6794 - val_loss: 0.6607 - val_acc: 0.5946\n",
      "Epoch 197/400\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 0.5708 - acc: 0.7634 - val_loss: 0.6602 - val_acc: 0.6036\n",
      "Epoch 198/400\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 0.6079 - acc: 0.6641 - val_loss: 0.6598 - val_acc: 0.6036\n",
      "Epoch 199/400\n",
      "1/1 [==============================] - 0s 477ms/step - loss: 0.6226 - acc: 0.7023 - val_loss: 0.6594 - val_acc: 0.6036\n",
      "Epoch 200/400\n",
      "1/1 [==============================] - 1s 514ms/step - loss: 0.5865 - acc: 0.6718 - val_loss: 0.6591 - val_acc: 0.6126\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.65876\n",
      "Epoch 201/400\n",
      "1/1 [==============================] - 0s 482ms/step - loss: 0.6015 - acc: 0.6641 - val_loss: 0.6590 - val_acc: 0.6126\n",
      "Epoch 202/400\n",
      "1/1 [==============================] - 0s 482ms/step - loss: 0.6231 - acc: 0.6947 - val_loss: 0.6592 - val_acc: 0.6126\n",
      "Epoch 203/400\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 0.5983 - acc: 0.6870 - val_loss: 0.6595 - val_acc: 0.6126\n",
      "Epoch 204/400\n",
      "1/1 [==============================] - 1s 512ms/step - loss: 0.5951 - acc: 0.6641 - val_loss: 0.6602 - val_acc: 0.6036\n",
      "Epoch 205/400\n",
      "1/1 [==============================] - 0s 499ms/step - loss: 0.6301 - acc: 0.6489 - val_loss: 0.6610 - val_acc: 0.5946\n",
      "Epoch 206/400\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 0.6066 - acc: 0.6794 - val_loss: 0.6621 - val_acc: 0.5856\n",
      "Epoch 207/400\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.6096 - acc: 0.6794 - val_loss: 0.6626 - val_acc: 0.5856\n",
      "Epoch 208/400\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 0.5814 - acc: 0.6794 - val_loss: 0.6628 - val_acc: 0.5856\n",
      "Epoch 209/400\n",
      "1/1 [==============================] - 0s 479ms/step - loss: 0.6142 - acc: 0.6412 - val_loss: 0.6629 - val_acc: 0.5856\n",
      "Epoch 210/400\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 0.6046 - acc: 0.6870 - val_loss: 0.6625 - val_acc: 0.5856\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.65876\n",
      "Epoch 211/400\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 0.6262 - acc: 0.6794 - val_loss: 0.6621 - val_acc: 0.5856\n",
      "Epoch 212/400\n",
      "1/1 [==============================] - 0s 491ms/step - loss: 0.6093 - acc: 0.6947 - val_loss: 0.6622 - val_acc: 0.5856\n",
      "Epoch 213/400\n",
      "1/1 [==============================] - 0s 487ms/step - loss: 0.6399 - acc: 0.6489 - val_loss: 0.6623 - val_acc: 0.5856\n",
      "Epoch 214/400\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 0.5898 - acc: 0.6870 - val_loss: 0.6621 - val_acc: 0.5856\n",
      "Epoch 215/400\n",
      "1/1 [==============================] - 0s 483ms/step - loss: 0.6140 - acc: 0.6412 - val_loss: 0.6619 - val_acc: 0.5856\n",
      "Epoch 216/400\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 0.5906 - acc: 0.7023 - val_loss: 0.6616 - val_acc: 0.5946\n",
      "Epoch 217/400\n",
      "1/1 [==============================] - 0s 487ms/step - loss: 0.5713 - acc: 0.6794 - val_loss: 0.6614 - val_acc: 0.6036\n",
      "Epoch 218/400\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 0.5546 - acc: 0.7252 - val_loss: 0.6614 - val_acc: 0.6036\n",
      "Epoch 219/400\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 0.6556 - acc: 0.6107 - val_loss: 0.6616 - val_acc: 0.6036\n",
      "Epoch 220/400\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 0.6117 - acc: 0.6947 - val_loss: 0.6621 - val_acc: 0.6036\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.65876\n",
      "Epoch 221/400\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 0.6093 - acc: 0.6794 - val_loss: 0.6627 - val_acc: 0.5856\n",
      "Epoch 222/400\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 0.5750 - acc: 0.7252 - val_loss: 0.6635 - val_acc: 0.5856\n",
      "Epoch 223/400\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 0.6228 - acc: 0.6641 - val_loss: 0.6640 - val_acc: 0.5766\n",
      "Epoch 224/400\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 0.5986 - acc: 0.6947 - val_loss: 0.6646 - val_acc: 0.5766\n",
      "Epoch 225/400\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.5719 - acc: 0.7099 - val_loss: 0.6645 - val_acc: 0.5766\n",
      "Epoch 226/400\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 0.5770 - acc: 0.7252 - val_loss: 0.6641 - val_acc: 0.5856\n",
      "Epoch 227/400\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 0.6337 - acc: 0.6641 - val_loss: 0.6631 - val_acc: 0.5946\n",
      "Epoch 228/400\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 0.6219 - acc: 0.6641 - val_loss: 0.6624 - val_acc: 0.5946\n",
      "Epoch 229/400\n",
      "1/1 [==============================] - 0s 442ms/step - loss: 0.6110 - acc: 0.6794 - val_loss: 0.6621 - val_acc: 0.5946\n",
      "Epoch 230/400\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 0.5862 - acc: 0.6489 - val_loss: 0.6622 - val_acc: 0.5946\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.65876\n",
      "Epoch 231/400\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 0.5821 - acc: 0.6870 - val_loss: 0.6628 - val_acc: 0.5946\n",
      "Epoch 232/400\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.5732 - acc: 0.7099 - val_loss: 0.6635 - val_acc: 0.5856\n",
      "Epoch 233/400\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 0.6118 - acc: 0.6641 - val_loss: 0.6641 - val_acc: 0.5766\n",
      "Epoch 234/400\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 0.5851 - acc: 0.7252 - val_loss: 0.6646 - val_acc: 0.5766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235/400\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 0.6457 - acc: 0.6565 - val_loss: 0.6646 - val_acc: 0.5766\n",
      "Epoch 236/400\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 0.6325 - acc: 0.6489 - val_loss: 0.6645 - val_acc: 0.5766\n",
      "Epoch 237/400\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 0.5663 - acc: 0.7328 - val_loss: 0.6640 - val_acc: 0.5856\n",
      "Epoch 238/400\n",
      "1/1 [==============================] - 0s 482ms/step - loss: 0.5942 - acc: 0.7023 - val_loss: 0.6631 - val_acc: 0.5946\n",
      "Epoch 239/400\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 0.5732 - acc: 0.7176 - val_loss: 0.6626 - val_acc: 0.5946\n",
      "Epoch 240/400\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 0.5805 - acc: 0.7405 - val_loss: 0.6623 - val_acc: 0.5946\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.65876\n",
      "Epoch 241/400\n",
      "1/1 [==============================] - 0s 430ms/step - loss: 0.6097 - acc: 0.6947 - val_loss: 0.6621 - val_acc: 0.5946\n",
      "Epoch 242/400\n",
      "1/1 [==============================] - 0s 433ms/step - loss: 0.5802 - acc: 0.6947 - val_loss: 0.6621 - val_acc: 0.5946\n",
      "Epoch 243/400\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 0.5914 - acc: 0.7252 - val_loss: 0.6624 - val_acc: 0.5946\n",
      "Epoch 244/400\n",
      "1/1 [==============================] - 0s 477ms/step - loss: 0.5942 - acc: 0.6947 - val_loss: 0.6627 - val_acc: 0.5946\n",
      "Epoch 245/400\n",
      "1/1 [==============================] - 0s 424ms/step - loss: 0.6030 - acc: 0.6947 - val_loss: 0.6631 - val_acc: 0.5946\n",
      "Epoch 246/400\n",
      "1/1 [==============================] - 0s 423ms/step - loss: 0.5697 - acc: 0.7252 - val_loss: 0.6634 - val_acc: 0.5946\n",
      "Epoch 247/400\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 0.5943 - acc: 0.6336 - val_loss: 0.6636 - val_acc: 0.5856\n",
      "Epoch 248/400\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.5894 - acc: 0.7099 - val_loss: 0.6639 - val_acc: 0.5856\n",
      "Epoch 249/400\n",
      "1/1 [==============================] - 1s 519ms/step - loss: 0.6048 - acc: 0.6641 - val_loss: 0.6634 - val_acc: 0.5946\n",
      "Epoch 250/400\n",
      "1/1 [==============================] - 0s 499ms/step - loss: 0.6018 - acc: 0.6794 - val_loss: 0.6628 - val_acc: 0.5946\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.65876\n",
      "Epoch 251/400\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 0.5960 - acc: 0.7176 - val_loss: 0.6619 - val_acc: 0.5946\n",
      "Epoch 252/400\n",
      "1/1 [==============================] - 1s 508ms/step - loss: 0.5931 - acc: 0.6489 - val_loss: 0.6611 - val_acc: 0.6036\n",
      "Epoch 253/400\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 0.5814 - acc: 0.7328 - val_loss: 0.6609 - val_acc: 0.6036\n",
      "Epoch 254/400\n",
      "1/1 [==============================] - 0s 490ms/step - loss: 0.6238 - acc: 0.6794 - val_loss: 0.6607 - val_acc: 0.6216\n",
      "Epoch 255/400\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 0.5989 - acc: 0.6870 - val_loss: 0.6607 - val_acc: 0.6126\n",
      "Epoch 256/400\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 0.6054 - acc: 0.6565 - val_loss: 0.6609 - val_acc: 0.6216\n",
      "Epoch 257/400\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 0.6129 - acc: 0.6183 - val_loss: 0.6613 - val_acc: 0.6036\n",
      "Epoch 258/400\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 0.6359 - acc: 0.6412 - val_loss: 0.6621 - val_acc: 0.5946\n",
      "Epoch 259/400\n",
      "1/1 [==============================] - 0s 432ms/step - loss: 0.6212 - acc: 0.6565 - val_loss: 0.6630 - val_acc: 0.5946\n",
      "Epoch 260/400\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 0.6058 - acc: 0.6336 - val_loss: 0.6640 - val_acc: 0.5946\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.65876\n",
      "Epoch 261/400\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 0.5740 - acc: 0.6870 - val_loss: 0.6647 - val_acc: 0.5856\n",
      "Epoch 262/400\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 0.6083 - acc: 0.6489 - val_loss: 0.6648 - val_acc: 0.5856\n",
      "Epoch 263/400\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 0.6271 - acc: 0.6336 - val_loss: 0.6647 - val_acc: 0.5856\n",
      "Epoch 264/400\n",
      "1/1 [==============================] - 0s 486ms/step - loss: 0.5988 - acc: 0.7252 - val_loss: 0.6646 - val_acc: 0.5766\n",
      "Epoch 265/400\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 0.6195 - acc: 0.6794 - val_loss: 0.6644 - val_acc: 0.5766\n",
      "Epoch 266/400\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 0.5556 - acc: 0.7634 - val_loss: 0.6641 - val_acc: 0.5856\n",
      "Epoch 267/400\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 0.6028 - acc: 0.6565 - val_loss: 0.6636 - val_acc: 0.5946\n",
      "Epoch 268/400\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 0.6071 - acc: 0.6947 - val_loss: 0.6631 - val_acc: 0.5946\n",
      "Epoch 269/400\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 0.6145 - acc: 0.6260 - val_loss: 0.6626 - val_acc: 0.5946\n",
      "Epoch 270/400\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 0.6203 - acc: 0.6412 - val_loss: 0.6619 - val_acc: 0.5946\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.65876\n",
      "Epoch 271/400\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.5991 - acc: 0.6641 - val_loss: 0.6617 - val_acc: 0.5946\n",
      "Epoch 272/400\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 0.5937 - acc: 0.6870 - val_loss: 0.6614 - val_acc: 0.5946\n",
      "Epoch 273/400\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 0.5795 - acc: 0.6870 - val_loss: 0.6611 - val_acc: 0.5946\n",
      "Epoch 274/400\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 0.6179 - acc: 0.6794 - val_loss: 0.6612 - val_acc: 0.5946\n",
      "Epoch 275/400\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 0.6162 - acc: 0.6641 - val_loss: 0.6614 - val_acc: 0.5946\n",
      "Epoch 276/400\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 0.6226 - acc: 0.6641 - val_loss: 0.6616 - val_acc: 0.5946\n",
      "Epoch 277/400\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 0.5439 - acc: 0.7634 - val_loss: 0.6621 - val_acc: 0.5946\n",
      "Epoch 278/400\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 0.5662 - acc: 0.7099 - val_loss: 0.6627 - val_acc: 0.5856\n",
      "Epoch 279/400\n",
      "1/1 [==============================] - 0s 480ms/step - loss: 0.5736 - acc: 0.7023 - val_loss: 0.6629 - val_acc: 0.5766\n",
      "Epoch 280/400\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 0.5760 - acc: 0.7176 - val_loss: 0.6629 - val_acc: 0.5766\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.65876\n",
      "Epoch 281/400\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 0.5829 - acc: 0.6870 - val_loss: 0.6625 - val_acc: 0.5856\n",
      "Epoch 282/400\n",
      "1/1 [==============================] - 0s 474ms/step - loss: 0.6367 - acc: 0.6641 - val_loss: 0.6618 - val_acc: 0.5946\n",
      "Epoch 283/400\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 0.5903 - acc: 0.6870 - val_loss: 0.6610 - val_acc: 0.5946\n",
      "Epoch 284/400\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 0.5599 - acc: 0.6947 - val_loss: 0.6602 - val_acc: 0.5946\n",
      "Epoch 285/400\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 0.6028 - acc: 0.7328 - val_loss: 0.6595 - val_acc: 0.6126\n",
      "Epoch 286/400\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 0.5900 - acc: 0.6870 - val_loss: 0.6591 - val_acc: 0.6036\n",
      "Epoch 287/400\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 0.6135 - acc: 0.6565 - val_loss: 0.6589 - val_acc: 0.6216\n",
      "Epoch 288/400\n",
      "1/1 [==============================] - 0s 477ms/step - loss: 0.5604 - acc: 0.7099 - val_loss: 0.6587 - val_acc: 0.6216\n",
      "Epoch 289/400\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 0.5539 - acc: 0.7405 - val_loss: 0.6586 - val_acc: 0.6216\n",
      "Epoch 290/400\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 0.6046 - acc: 0.6870 - val_loss: 0.6586 - val_acc: 0.6036\n",
      "\n",
      "Epoch 00290: val_loss improved from 0.65876 to 0.65865, saving model to models/cat_dog_classfication_aug_gray_model.hdf5\n",
      "Epoch 291/400\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 0.6137 - acc: 0.6565 - val_loss: 0.6590 - val_acc: 0.6126\n",
      "Epoch 292/400\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 0.5509 - acc: 0.7252 - val_loss: 0.6596 - val_acc: 0.5946\n",
      "Epoch 293/400\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 0.5990 - acc: 0.6794 - val_loss: 0.6604 - val_acc: 0.5946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 294/400\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 0.5664 - acc: 0.7176 - val_loss: 0.6612 - val_acc: 0.5946\n",
      "Epoch 295/400\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 0.6034 - acc: 0.6870 - val_loss: 0.6618 - val_acc: 0.5766\n",
      "Epoch 296/400\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 0.6002 - acc: 0.7328 - val_loss: 0.6619 - val_acc: 0.5766\n",
      "Epoch 297/400\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 0.5718 - acc: 0.7328 - val_loss: 0.6617 - val_acc: 0.5856\n",
      "Epoch 298/400\n",
      "1/1 [==============================] - 0s 484ms/step - loss: 0.6280 - acc: 0.5954 - val_loss: 0.6615 - val_acc: 0.5856\n",
      "Epoch 299/400\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 0.5864 - acc: 0.7176 - val_loss: 0.6614 - val_acc: 0.5946\n",
      "Epoch 300/400\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 0.5737 - acc: 0.6794 - val_loss: 0.6614 - val_acc: 0.5946\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.65865\n",
      "Epoch 301/400\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 0.5933 - acc: 0.7023 - val_loss: 0.6615 - val_acc: 0.5946\n",
      "Epoch 302/400\n",
      "1/1 [==============================] - 0s 480ms/step - loss: 0.5165 - acc: 0.7481 - val_loss: 0.6618 - val_acc: 0.5856\n",
      "Epoch 303/400\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 0.6090 - acc: 0.7023 - val_loss: 0.6623 - val_acc: 0.5766\n",
      "Epoch 304/400\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 0.6049 - acc: 0.7099 - val_loss: 0.6629 - val_acc: 0.5856\n",
      "Epoch 305/400\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.6129 - acc: 0.6794 - val_loss: 0.6631 - val_acc: 0.5856\n",
      "Epoch 306/400\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 0.6121 - acc: 0.6641 - val_loss: 0.6632 - val_acc: 0.5856\n",
      "Epoch 307/400\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 0.5955 - acc: 0.6565 - val_loss: 0.6634 - val_acc: 0.5856\n",
      "Epoch 308/400\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 0.5903 - acc: 0.6718 - val_loss: 0.6633 - val_acc: 0.5766\n",
      "Epoch 309/400\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 0.5647 - acc: 0.7252 - val_loss: 0.6632 - val_acc: 0.5766\n",
      "Epoch 310/400\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.5935 - acc: 0.7405 - val_loss: 0.6632 - val_acc: 0.5766\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.65865\n",
      "Epoch 311/400\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 0.5827 - acc: 0.7405 - val_loss: 0.6630 - val_acc: 0.5856\n",
      "Epoch 312/400\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 0.6250 - acc: 0.7176 - val_loss: 0.6628 - val_acc: 0.5856\n",
      "Epoch 313/400\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 0.6059 - acc: 0.6718 - val_loss: 0.6627 - val_acc: 0.5946\n",
      "Epoch 314/400\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 0.5803 - acc: 0.7176 - val_loss: 0.6624 - val_acc: 0.5946\n",
      "Epoch 315/400\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 0.5665 - acc: 0.7634 - val_loss: 0.6622 - val_acc: 0.5946\n",
      "Epoch 316/400\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 0.6124 - acc: 0.7023 - val_loss: 0.6621 - val_acc: 0.5946\n",
      "Epoch 317/400\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 0.5647 - acc: 0.7405 - val_loss: 0.6616 - val_acc: 0.5946\n",
      "Epoch 318/400\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 0.6192 - acc: 0.6489 - val_loss: 0.6614 - val_acc: 0.6036\n",
      "Epoch 319/400\n",
      "1/1 [==============================] - 0s 441ms/step - loss: 0.6161 - acc: 0.6412 - val_loss: 0.6612 - val_acc: 0.6036\n",
      "Epoch 320/400\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 0.5674 - acc: 0.7405 - val_loss: 0.6613 - val_acc: 0.6036\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.65865\n",
      "Epoch 321/400\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 0.5543 - acc: 0.7634 - val_loss: 0.6614 - val_acc: 0.6036\n",
      "Epoch 322/400\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 0.5755 - acc: 0.7023 - val_loss: 0.6618 - val_acc: 0.5946\n",
      "Epoch 323/400\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 0.6122 - acc: 0.6794 - val_loss: 0.6626 - val_acc: 0.5946\n",
      "Epoch 324/400\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.5607 - acc: 0.7481 - val_loss: 0.6636 - val_acc: 0.5856\n",
      "Epoch 325/400\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 0.5895 - acc: 0.7023 - val_loss: 0.6645 - val_acc: 0.5766\n",
      "Epoch 326/400\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 0.5656 - acc: 0.7252 - val_loss: 0.6651 - val_acc: 0.5856\n",
      "Epoch 327/400\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 0.5471 - acc: 0.7252 - val_loss: 0.6653 - val_acc: 0.5856\n",
      "Epoch 328/400\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 0.5820 - acc: 0.7023 - val_loss: 0.6650 - val_acc: 0.5856\n",
      "Epoch 329/400\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 0.6102 - acc: 0.6794 - val_loss: 0.6642 - val_acc: 0.5856\n",
      "Epoch 330/400\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 0.5740 - acc: 0.7023 - val_loss: 0.6633 - val_acc: 0.5946\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.65865\n",
      "Epoch 331/400\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 0.5671 - acc: 0.7405 - val_loss: 0.6627 - val_acc: 0.5946\n",
      "Epoch 332/400\n",
      "1/1 [==============================] - 0s 491ms/step - loss: 0.6124 - acc: 0.6718 - val_loss: 0.6625 - val_acc: 0.5946\n",
      "Epoch 333/400\n",
      "1/1 [==============================] - 0s 458ms/step - loss: 0.6488 - acc: 0.6336 - val_loss: 0.6624 - val_acc: 0.5946\n",
      "Epoch 334/400\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 0.6279 - acc: 0.6794 - val_loss: 0.6625 - val_acc: 0.5946\n",
      "Epoch 335/400\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 0.5575 - acc: 0.7099 - val_loss: 0.6629 - val_acc: 0.5946\n",
      "Epoch 336/400\n",
      "1/1 [==============================] - 0s 446ms/step - loss: 0.5788 - acc: 0.6565 - val_loss: 0.6633 - val_acc: 0.5946\n",
      "Epoch 337/400\n",
      "1/1 [==============================] - 0s 435ms/step - loss: 0.6050 - acc: 0.6718 - val_loss: 0.6639 - val_acc: 0.5946\n",
      "Epoch 338/400\n",
      "1/1 [==============================] - 0s 450ms/step - loss: 0.5921 - acc: 0.7176 - val_loss: 0.6646 - val_acc: 0.5856\n",
      "Epoch 339/400\n",
      "1/1 [==============================] - 0s 477ms/step - loss: 0.6331 - acc: 0.6336 - val_loss: 0.6659 - val_acc: 0.5856\n",
      "Epoch 340/400\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.5878 - acc: 0.7328 - val_loss: 0.6672 - val_acc: 0.5946\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.65865\n",
      "Epoch 341/400\n",
      "1/1 [==============================] - 0s 470ms/step - loss: 0.5957 - acc: 0.6947 - val_loss: 0.6683 - val_acc: 0.5946\n",
      "Epoch 342/400\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 0.5776 - acc: 0.7405 - val_loss: 0.6683 - val_acc: 0.6036\n",
      "Epoch 343/400\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 0.6002 - acc: 0.6641 - val_loss: 0.6673 - val_acc: 0.5946\n",
      "Epoch 344/400\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 0.6250 - acc: 0.6641 - val_loss: 0.6663 - val_acc: 0.5946\n",
      "Epoch 345/400\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.5574 - acc: 0.7557 - val_loss: 0.6648 - val_acc: 0.5856\n",
      "Epoch 346/400\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 0.5865 - acc: 0.7099 - val_loss: 0.6635 - val_acc: 0.5946\n",
      "Epoch 347/400\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 0.5534 - acc: 0.7481 - val_loss: 0.6626 - val_acc: 0.5856\n",
      "Epoch 348/400\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 0.5729 - acc: 0.7023 - val_loss: 0.6621 - val_acc: 0.5856\n",
      "Epoch 349/400\n",
      "1/1 [==============================] - 0s 479ms/step - loss: 0.6198 - acc: 0.6870 - val_loss: 0.6618 - val_acc: 0.5946\n",
      "Epoch 350/400\n",
      "1/1 [==============================] - 0s 469ms/step - loss: 0.5916 - acc: 0.6870 - val_loss: 0.6616 - val_acc: 0.6036\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.65865\n",
      "Epoch 351/400\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 0.6140 - acc: 0.6794 - val_loss: 0.6615 - val_acc: 0.6126\n",
      "Epoch 352/400\n",
      "1/1 [==============================] - 0s 499ms/step - loss: 0.5757 - acc: 0.7252 - val_loss: 0.6615 - val_acc: 0.6126\n",
      "Epoch 353/400\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 0.6110 - acc: 0.6336 - val_loss: 0.6616 - val_acc: 0.6036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 354/400\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 0.5585 - acc: 0.7176 - val_loss: 0.6617 - val_acc: 0.5856\n",
      "Epoch 355/400\n",
      "1/1 [==============================] - 0s 475ms/step - loss: 0.6567 - acc: 0.6336 - val_loss: 0.6621 - val_acc: 0.5856\n",
      "Epoch 356/400\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 0.5768 - acc: 0.7405 - val_loss: 0.6627 - val_acc: 0.5946\n",
      "Epoch 357/400\n",
      "1/1 [==============================] - 0s 462ms/step - loss: 0.5876 - acc: 0.6565 - val_loss: 0.6634 - val_acc: 0.5946\n",
      "Epoch 358/400\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 0.5513 - acc: 0.7634 - val_loss: 0.6638 - val_acc: 0.5856\n",
      "Epoch 359/400\n",
      "1/1 [==============================] - 1s 556ms/step - loss: 0.5879 - acc: 0.7481 - val_loss: 0.6641 - val_acc: 0.5856\n",
      "Epoch 360/400\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 0.6104 - acc: 0.7099 - val_loss: 0.6641 - val_acc: 0.5856\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.65865\n",
      "Epoch 361/400\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.5584 - acc: 0.7252 - val_loss: 0.6641 - val_acc: 0.5856\n",
      "Epoch 362/400\n",
      "1/1 [==============================] - 0s 476ms/step - loss: 0.5502 - acc: 0.7176 - val_loss: 0.6639 - val_acc: 0.5856\n",
      "Epoch 363/400\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 0.5476 - acc: 0.7328 - val_loss: 0.6640 - val_acc: 0.5856\n",
      "Epoch 364/400\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 0.5674 - acc: 0.7176 - val_loss: 0.6637 - val_acc: 0.5856\n",
      "Epoch 365/400\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 0.6071 - acc: 0.6947 - val_loss: 0.6634 - val_acc: 0.5856\n",
      "Epoch 366/400\n",
      "1/1 [==============================] - 0s 459ms/step - loss: 0.6085 - acc: 0.7099 - val_loss: 0.6630 - val_acc: 0.5856\n",
      "Epoch 367/400\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 0.6299 - acc: 0.6412 - val_loss: 0.6628 - val_acc: 0.5946\n",
      "Epoch 368/400\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 0.5593 - acc: 0.7176 - val_loss: 0.6627 - val_acc: 0.5946\n",
      "Epoch 369/400\n",
      "1/1 [==============================] - 0s 452ms/step - loss: 0.5685 - acc: 0.7023 - val_loss: 0.6629 - val_acc: 0.5856\n",
      "Epoch 370/400\n",
      "1/1 [==============================] - 0s 473ms/step - loss: 0.5486 - acc: 0.7557 - val_loss: 0.6636 - val_acc: 0.5856\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.65865\n",
      "Epoch 371/400\n",
      "1/1 [==============================] - 0s 453ms/step - loss: 0.5756 - acc: 0.7252 - val_loss: 0.6645 - val_acc: 0.5856\n",
      "Epoch 372/400\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 0.5989 - acc: 0.7176 - val_loss: 0.6658 - val_acc: 0.6126\n",
      "Epoch 373/400\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 0.6014 - acc: 0.7099 - val_loss: 0.6669 - val_acc: 0.6036\n",
      "Epoch 374/400\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 0.5775 - acc: 0.7023 - val_loss: 0.6675 - val_acc: 0.5946\n",
      "Epoch 375/400\n",
      "1/1 [==============================] - 0s 447ms/step - loss: 0.5511 - acc: 0.6947 - val_loss: 0.6677 - val_acc: 0.5946\n",
      "Epoch 376/400\n",
      "1/1 [==============================] - 0s 468ms/step - loss: 0.5872 - acc: 0.6947 - val_loss: 0.6675 - val_acc: 0.5946\n",
      "Epoch 377/400\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.5914 - acc: 0.6260 - val_loss: 0.6671 - val_acc: 0.6126\n",
      "Epoch 378/400\n",
      "1/1 [==============================] - 0s 443ms/step - loss: 0.5892 - acc: 0.7328 - val_loss: 0.6662 - val_acc: 0.6126\n",
      "Epoch 379/400\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 0.5327 - acc: 0.7481 - val_loss: 0.6654 - val_acc: 0.6036\n",
      "Epoch 380/400\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 0.6059 - acc: 0.7176 - val_loss: 0.6649 - val_acc: 0.5856\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 0.65865\n",
      "Epoch 381/400\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 0.5891 - acc: 0.7252 - val_loss: 0.6642 - val_acc: 0.5856\n",
      "Epoch 382/400\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 0.5674 - acc: 0.7099 - val_loss: 0.6635 - val_acc: 0.5856\n",
      "Epoch 383/400\n",
      "1/1 [==============================] - 0s 478ms/step - loss: 0.5937 - acc: 0.7023 - val_loss: 0.6631 - val_acc: 0.5856\n",
      "Epoch 384/400\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 0.5910 - acc: 0.7023 - val_loss: 0.6631 - val_acc: 0.5856\n",
      "Epoch 385/400\n",
      "1/1 [==============================] - 0s 490ms/step - loss: 0.5282 - acc: 0.7634 - val_loss: 0.6632 - val_acc: 0.5856\n",
      "Epoch 386/400\n",
      "1/1 [==============================] - 0s 466ms/step - loss: 0.5637 - acc: 0.7252 - val_loss: 0.6634 - val_acc: 0.5856\n",
      "Epoch 387/400\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 0.5979 - acc: 0.6565 - val_loss: 0.6638 - val_acc: 0.5856\n",
      "Epoch 388/400\n",
      "1/1 [==============================] - 1s 566ms/step - loss: 0.6290 - acc: 0.6794 - val_loss: 0.6643 - val_acc: 0.5856\n",
      "Epoch 389/400\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 0.6056 - acc: 0.6641 - val_loss: 0.6646 - val_acc: 0.5856\n",
      "Epoch 390/400\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 0.5680 - acc: 0.7176 - val_loss: 0.6647 - val_acc: 0.5856\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.65865\n",
      "Epoch 391/400\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 0.6088 - acc: 0.7023 - val_loss: 0.6646 - val_acc: 0.5856\n",
      "Epoch 392/400\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 0.5706 - acc: 0.7099 - val_loss: 0.6643 - val_acc: 0.5856\n",
      "Epoch 393/400\n",
      "1/1 [==============================] - 0s 463ms/step - loss: 0.5629 - acc: 0.7252 - val_loss: 0.6638 - val_acc: 0.5856\n",
      "Epoch 394/400\n",
      "1/1 [==============================] - 0s 464ms/step - loss: 0.5730 - acc: 0.7405 - val_loss: 0.6632 - val_acc: 0.5856\n",
      "Epoch 395/400\n",
      "1/1 [==============================] - 0s 479ms/step - loss: 0.5486 - acc: 0.7405 - val_loss: 0.6627 - val_acc: 0.5946\n",
      "Epoch 396/400\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 0.6030 - acc: 0.6718 - val_loss: 0.6625 - val_acc: 0.6036\n",
      "Epoch 397/400\n",
      "1/1 [==============================] - 0s 456ms/step - loss: 0.5705 - acc: 0.6794 - val_loss: 0.6625 - val_acc: 0.6036\n",
      "Epoch 398/400\n",
      "1/1 [==============================] - 0s 449ms/step - loss: 0.5626 - acc: 0.7023 - val_loss: 0.6629 - val_acc: 0.5946\n",
      "Epoch 399/400\n",
      "1/1 [==============================] - 0s 479ms/step - loss: 0.5512 - acc: 0.7099 - val_loss: 0.6638 - val_acc: 0.5856\n",
      "Epoch 400/400\n",
      "1/1 [==============================] - 0s 455ms/step - loss: 0.6152 - acc: 0.6641 - val_loss: 0.6650 - val_acc: 0.5766\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.65865\n"
     ]
    }
   ],
   "source": [
    "remove_log_files('logs/')\n",
    "if USE_DATAGEN:\n",
    "    history = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=BATCH_SIZE), epochs=NB_EPOCH * 4, verbose=VERBOSE, validation_data=(X_valid, Y_valid), shuffle=True, callbacks=callbacks, steps_per_epoch=1)\n",
    "else:\n",
    "    history = model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=NB_EPOCH * 4, verbose=VERBOSE, validation_data=(X_valid, Y_valid), shuffle=True, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 1ms/step\n",
      "Test score: 0.7275596857070923\n",
      "Test acc: 0.5283018873547608\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=VERBOSE)\n",
    "print('Test score:', score[0])\n",
    "print('Test acc:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(121)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model acc')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig('chart/aug_gray.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_dataのacc, lossは順調に推移するが、val_dataに対しては一定幅で同水準に留まる。\n",
    "元データが少ないから？(https://datascience.stackexchange.com/questions/37815/what-to-do-if-training-loss-decreases-but-validation-loss-does-not-decrease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_answers = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid dimensions for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-60e10dc5a582>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'answer is dog, but cat is predicted:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_wrong_cnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.6/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2651\u001b[0m         \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2652\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2653\u001b[0;31m         resample=resample, url=url, data=data, **kwargs)\n\u001b[0m\u001b[1;32m   2654\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2655\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.6/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1783\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1784\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1785\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1787\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.6/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5470\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5472\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5473\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.6/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    644\u001b[0m         if not (self._A.ndim == 2\n\u001b[1;32m    645\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[0;32m--> 646\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid dimensions for image data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid dimensions for image data"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAEVCAYAAADAYlikAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAACDBJREFUeJzt3FusbPcAx/HfX3ukVaqqFxGXSqpUXIoUESIaXiRuISWEujx48OASUQSJxiWSpngSXoQHKjx4ICIuKSIuaSRoIg1SdRchWq1bqn8PMyf2nu7uM/ucfc4+4/f5JDt71sys/1o7O9+ZNWvNWmPOGaDLPQ56BYATT/hQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPgcd2OM68YYc/nzy4NeH4QPlYQPhYQPhYQPhYQPhU496BXg2I0xTknyxCQPT3JukjOS/C3JL5P8aM558x7GOiPJo5M8Isk5SU5PckuSPyW5fs75i31deQ7EcCGOzTXGuDDJO5O8IMl9d3nqz5N8LslH55y/3mGchyZ5aZLnJnlSkkO7jHVzkg8n+dic8x+7rNurknziCH/CTp4557zuKOZjD7zjb6AxxkhyVZK3Zb3/4YVJ3p7kXkneuDLWKUluSjLWXPxDk3woyavGGM/fy9YEJw/hb5hlqNcmefEOD9+Yxbv7LUnOzGLT/6LsHvVYeXxm8ULwsyR/XU6fk+SS5e/DHpfkq2OMJ8w5bzuqP4YDI/zNc1W2Rz+z2KR+75zzptUnjzHOTvLCJK/bZcw7knwhi48DX5lz3rLDOPdI8uwkV2exDyBZvLB8MMnrdxjz80muW96+NsmTl7d/m+Rpu6zLH3Z5jH3iM/4GGWNcmuT7+d879B1JrphzfnrN+c+fc/5x5b6R5MFzzl+tOcYZSb6W5CnLu/6R5EFzzr/sMs91SZ6xnLx5znnBOsvi+HE4b7O8I9s3y9+3bvRJshr98r65bvTL59+e7VsPpyd53rrzc3IQ/oYYY5yX5Plb7vpjkvcfxLrMOX+cxX6Aw558d8/l5OQz/uZ4Rra/239qzvnv47nAMcZpWewkPD133UH45yQPW95+5PFcD/af8DfH6rvqt/d7AWOMhyd5WZJnJnlMkrPXnPV++70uHF/C3xwPWJn+6X4NPMY4K4u99a/J+sfztzpzv9aFE0P4m+P+K9N/3Y9Bxxj3S/L1JI8/hmHsK9ow/mGba7+Ow16T7dH/M8mnkrxief/5WXz3/5Q55zj8k+Sb+7R8DoB3/M2xepz8rCx2sB21McaDk1yx5a7fJblsznnjGrPf51iWzcHyjr85Vr/RdvE+jPmcbP9M/9Y1o0/uus+BDSL8zfHdlemn78OYF65Mf2WdmZZbCg/cw3J8PfQkI/zN8c0kd26ZfuUYY7fTZ9exeirvrWvO9/I9LudfW27fc4/zchwIf0PMOf+UxYk0hz0gi9Nyj8XqkYGLjjTDGOPcJG/a43K2nvRzzvIMQw6Q8DfLB7J9s/ndY4yXrDvzGOP8lbt+sjL95iPMf68szrQ7b91lLm3db3Aou5+dxwkg/A0y57w+27+ff2qSz4wxPj7GuGCnecYYZ48xXjPG+EEWF+PY6stJ/r5l+tVjjGvGGHfZYz/GeHqS7yS5LIsXn70cUfjWyvQnxxivHWNcMsZ42Bjjgi0/p+1hXI6S03I3zHIz+bNJXrTDwz/N4kIct2b7hTgOv8B/ZM65egWeq5K8a2Wc25J8L4sTgc7M4qIbD9ny+NVJLs2ap9ouT/29Icmjdv/rkrj01gnhOP6GmXP+Z4xxeRab/W/J9q22i7P3w3zvWc6z9eIe907yrLt5/seTXJnkG+suYM45lx9JvpTtLyAcEJv6G2jOeeec88osTqT5bJLbjzDLjVkE/sEdxvpPksuTvCG7X/3mu0leNOd83Zzzzl2ed3frfMNyfV+f5ItZXAH4tjjUdyBs6v8fGGPcM8lTk1yQxeW1D2WxuX9TFpfX/s2a4xzK4iq7j83ijLtbk/w+yQ93uqwXm0v4UMimPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhQSPhT6L6gqOGIiChsmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 3600x3600 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(50,50))\n",
    "columns = 5\n",
    "cat_wrong_cnt = 0\n",
    "dog_wrong_cnt = 0\n",
    "for i, image in enumerate(X_test):\n",
    "    plt.subplot(len(X_test) / columns + 1, columns, i + 1)\n",
    "    predicted_num = predict_answers[i]\n",
    "    answer = y_test[i]\n",
    "    \n",
    "    if predicted_num != answer:\n",
    "        if predicted_num == 0:\n",
    "            label = 'cat'\n",
    "            cat_wrong_cnt += 1\n",
    "        else:\n",
    "            label = 'dog'\n",
    "            dog_wrong_cnt += 1\n",
    "        plt.title(label, fontsize=40)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(image)\n",
    "\n",
    "print('answer is dog, but cat is predicted:', cat_wrong_cnt)\n",
    "print('answer is cat, but dog is predicted:', dog_wrong_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像加工 min val-loss, filters, dropout, note<br>\n",
    "gray 0.69, 16, 0.3, epoch50くらいで過学習<br>\n",
    "color 0.59, 16, 0.3, epoch180くらいで過学習<br>\n",
    "aug, 0.61, 16, 0.3, epoch180くらいで過学習<br>\n",
    "gray & aug<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
